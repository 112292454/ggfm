

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Advanced Mini-Batching &mdash; GGFM 0.1 文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=04b44b89"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
      <script src="../_static/translations.js?v=beaddf03"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="gammagl.datasets" href="../api/gammagl.datasets.html" />
    <link rel="prev" title="Creating Message Passing Networks" href="create_gnn.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            GGFM
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NOTES</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction by Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="create_dataset.html">Creating Your Own Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="create_gnn.html">Creating Message Passing Networks</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Advanced Mini-Batching</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#pairs-of-graphs">Pairs of Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bipartite-graphs">Bipartite Graphs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#batching-along-new-dimensions">Batching Along New Dimensions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/gammagl.datasets.html">gammagl.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/gammagl.layers.html">gammagl.layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/gammagl.loader.html">gammagl.loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/gammagl.transforms.html">gammagl.transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/gammagl.utils.html">gammagl.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">GGFM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Advanced Mini-Batching</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notes/batching.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="advanced-mini-batching">
<h1>Advanced Mini-Batching<a class="headerlink" href="#advanced-mini-batching" title="此标题的永久链接">¶</a></h1>
<p>The creation of mini-batching is crucial for letting the training of a
deep learning model scale to huge amounts of data. Instead of processing
examples one-by-one, a mini-batch groups a set of examples into a unified
representation where it can efficiently be processed in parallel.
In the image or language domain, this procedure is typically achieved by
rescaling or padding each example into a set to equally-sized shapes, and
examples are then grouped in an additional dimension. The length of this
dimension is then equal to the number of examples grouped in a mini-batch
and is typically referred to as the <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_size</span></code>.</p>
<p>Since graphs are one of the most general data structures that can hold any number of nodes or edges, the two approaches described above are either not feasible or may result in a lot of unnecessary memory consumption.
In GammaGL, we opt for another approach to achieve parallelization across a number of examples. Here, adjacency matrices are stacked in a diagonal fashion (creating a giant graph that holds multiple isolated subgraphs), and node and target features are simply concatenated in the node dimension, i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mathbf{A} = \begin{bmatrix} \mathbf{A}_1 &amp; &amp; \\ &amp; \ddots &amp; \\ &amp; &amp; \mathbf{A}_n \end{bmatrix}, \qquad \mathbf{X} = \begin{bmatrix} \mathbf{X}_1 \\ \vdots \\ \mathbf{X}_n \end{bmatrix}, \qquad \mathbf{Y} = \begin{bmatrix} \mathbf{Y}_1 \\ \vdots \\ \mathbf{Y}_n \end{bmatrix}.\end{split}\]</div>
<p>This procedure has some crucial advantages over other batching procedures:</p>
<ol class="arabic simple">
<li><p>GNN operators that rely on a message passing scheme do not need to be modified since messages still cannot be exchanged between two nodes that belong to different graphs.</p></li>
<li><p>There is no computational or memory overhead. For example, this batching procedure works completely without any padding of node or edge features. Note that there is no additional memory overhead for adjacency matrices since they are saved in a sparse fashion holding only non-zero entries, i.e., the edges.</p></li>
</ol>
<p>GammaGL automatically takes care of batching multiple graphs into a single
giant graph with the help of the <code class="xref py py-class docutils literal notranslate"><span class="pre">gammagl.loader.DataLoader</span></code> class.
Internally, <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> is just a regular TensorLayerx <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorlayerx.dataflow.DataLoader</span></code>
that overwrites its <code class="xref py py-func docutils literal notranslate"><span class="pre">collate()</span></code> functionality, i.e.,
the definition of how a list of examples should be grouped together.
Therefore, all arguments that can be passed to a TensorLayerx <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>
can also be passed to a GammaGL <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code>, e.g., the number of workers
<code class="xref py py-obj docutils literal notranslate"><span class="pre">num_workers</span></code>.</p>
<p>In its most general form, the GammaGL <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> will automatically
increment the <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> tensor by the cumulated number of nodes of all
graphs that got collated before the currently processed graph,
and will concatenate <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> tensors (that are of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">num_edges]</span></code>)
in the second dimension. The same is true for <code class="xref py py-obj docutils literal notranslate"><span class="pre">face</span></code> tensors, i.e.,
face indices in meshes. All other tensors will just get concatenated in
the first dimension without any further increasement of their values.</p>
<p>However, there are a few special use-cases (as outlined below) where the
user actively wants to modify this behaviour to its own needs. GammaGl
allows modification to the underlying batching procedure by overwriting
the <code class="xref py py-func docutils literal notranslate"><span class="pre">gammagl.data.Graph.__inc__()</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">gammagl.data.Graph.__cat_dim__()</span></code>
functionalities. Without any modifications, these are defined as follows
in the <code class="xref py py-class docutils literal notranslate"><span class="pre">Graph</span></code> class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">__inc__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;index&#39;</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">or</span> <span class="s1">&#39;face&#39;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">__cat_dim__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;index&#39;</span> <span class="ow">in</span> <span class="n">key</span> <span class="ow">or</span> <span class="s1">&#39;face&#39;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</pre></div>
</div>
<p>We can see that <code class="xref py py-meth docutils literal notranslate"><span class="pre">__inc__()</span></code> defines the incremental count between two
consecutive graph attributes, where as <code class="xref py py-meth docutils literal notranslate"><span class="pre">__cat_dim__()</span></code> defines in which
dimension graph tensors of the same attribute should be concatenated
together. Both functions are called for each attribute stored in the
<code class="xref py py-class docutils literal notranslate"><span class="pre">Graph</span></code> class, and get passed their specific <code class="xref py py-obj docutils literal notranslate"><span class="pre">key</span></code> and value <code class="xref py py-obj docutils literal notranslate"><span class="pre">item</span></code> as arguments.</p>
<p>In what follows, we present a few use-cases where the modification
of <code class="xref py py-func docutils literal notranslate"><span class="pre">__inc__()</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">__cat_dim__()</span></code> might be absolutely necessary</p>
<section id="pairs-of-graphs">
<h2>Pairs of Graphs<a class="headerlink" href="#pairs-of-graphs" title="此标题的永久链接">¶</a></h2>
<p>In case you want to store multiple graphs in a single <code class="xref py py-class docutils literal notranslate"><span class="pre">Graph</span></code> object, e.g.,
for applications such as graph matching, you need to ensure correct
batching behaviour across all those graphs. For example, consider storing
two graphs, a source graph <span class="math notranslate nohighlight">\($\mathcal{G}_{s}$\)</span> and a target graph
:math: <cite>$mathcal{G}_{t}$`in a `Graph</cite>, e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gammagl.data</span> <span class="kn">import</span> <span class="n">Graph</span>

<span class="k">class</span> <span class="nc">PairGraph</span><span class="p">(</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_index_s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_index_t</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_index_s</span> <span class="o">=</span> <span class="n">edge_index_s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_s</span> <span class="o">=</span> <span class="n">x_s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_index_t</span> <span class="o">=</span> <span class="n">edge_index_t</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span>
</pre></div>
</div>
<p>In this case, <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index_s</span></code> should be increased by the number of nodes in the source graph <span class="math notranslate nohighlight">\(\mathcal{G}_s\)</span>, <em>e.g.</em>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_s.size(0)</span></code>, and <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index_t</span></code> should be increased by the number of nodes in the target graph <span class="math notranslate nohighlight">\(\mathcal{G}_t\)</span>, <em>e.g.</em>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_t.size(0)</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">__inc__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;edge_index_s&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">)]</span>
    <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;edge_index_t&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__inc__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<p>We can test our <code class="xref py py-class docutils literal notranslate"><span class="pre">PairGraph</span></code> batching behaviour by setting up a simple test script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gammagl.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>

 <span class="n">edge_index_s</span> <span class="o">=</span> <span class="n">tlx</span><span class="o">.</span><span class="n">conver_to_tensor</span><span class="p">([</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
 <span class="p">])</span>
 <span class="n">x_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>  <span class="c1"># 5 nodes.</span>
 <span class="n">edge_index_t</span> <span class="o">=</span> <span class="n">tlx</span><span class="o">.</span><span class="n">conver_to_tensor</span><span class="p">([</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
 <span class="p">])</span>
 <span class="n">x_t</span> <span class="o">=</span> <span class="n">tlx</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>  <span class="c1"># 4 nodes.</span>

 <span class="n">graph</span> <span class="o">=</span> <span class="n">PairGraph</span><span class="p">(</span><span class="n">edge_index_s</span><span class="p">,</span> <span class="n">x_s</span><span class="p">,</span> <span class="n">edge_index_t</span><span class="p">,</span> <span class="n">x_t</span><span class="p">)</span>
 <span class="n">Graph_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">graph</span><span class="p">,</span> <span class="n">graph</span><span class="p">]</span>
 <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">data_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
 <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>

 <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
 <span class="o">&gt;&gt;&gt;</span> <span class="n">PairGraphBatch</span><span class="p">(</span><span class="n">edge_index_s</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">x_s</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span>
                   <span class="n">edge_index_t</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">x_t</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>

 <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">edge_index_s</span><span class="p">)</span>
 <span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]])</span>

 <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">edge_index_t</span><span class="p">)</span>
 <span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]])</span>
</pre></div>
</div>
<p>Everything looks good so far!
<code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index_s</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index_t</span></code> get correctly batched together, even when using different numbers of nodes for <span class="math notranslate nohighlight">\(\mathcal{G}_s\)</span> and <span class="math notranslate nohighlight">\(\mathcal{G}_t\)</span>.
However, the <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch</span></code> attribute (that maps each node to its respective graph) is missing since PyG fails to identify the actual graph in the <code class="xref py py-class docutils literal notranslate"><span class="pre">PairGraph</span></code> object.
That’s where the <code class="xref py py-obj docutils literal notranslate"><span class="pre">follow_batch</span></code> argument of the <code class="xref py py-class docutils literal notranslate"><span class="pre">gammagl.loader.DataLoader</span></code> comes into play.
Here, we can specify for which attributes we want to maintain the batch information:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">Graph_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">follow_batch</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;x_s&#39;</span><span class="p">,</span> <span class="s1">&#39;x_t&#39;</span><span class="p">])</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">PairGraphBatch</span><span class="p">(</span><span class="n">edge_index_s</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">x_s</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">x_s_batch</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">],</span>
                  <span class="n">edge_index_t</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">x_t</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">x_t_batch</span><span class="o">=</span><span class="p">[</span><span class="mi">8</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">x_s_batch</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">x_t_batch</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>As one can see, <code class="xref py py-obj docutils literal notranslate"><span class="pre">follow_batch=['x_s',</span> <span class="pre">'x_t']</span></code> now successfully creates assignment vectors called <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_s_batch</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_t_batch</span></code> for the node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_s</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_t</span></code>, respectively.
That information can now be used to perform reduce operations, <em>e.g.</em>, global pooling, on multiple graphs in a single <code class="xref py py-class docutils literal notranslate"><span class="pre">Batch</span></code> object.</p>
</section>
<section id="bipartite-graphs">
<h2>Bipartite Graphs<a class="headerlink" href="#bipartite-graphs" title="此标题的永久链接">¶</a></h2>
<p>The adjacency matrix of a bipartite graph defines the relationship between nodes of two different node types.
In general, the number of nodes for each node type do not need to match, resulting in a non-quadratic adjacency matrix of
shape <span class="math notranslate nohighlight">\(\mathbf{A} \in \{ 0, 1 \}^{N \times M}\)</span> with <span class="math notranslate nohighlight">\(N \neq M\)</span> potentially.
In a mini-batching procedure of bipartite graphs, the source nodes of edges in <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> should get increased differently than the
target nodes of edges in <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code>.
To achieve this, consider a bipartite graph between two node types with corresponding node features <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_s</span></code> and <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_t</span></code>, respectively:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gammagl.data</span> <span class="kn">import</span> <span class="n">Graph</span>

<span class="k">class</span> <span class="nc">BipartiteGraph</span><span class="p">(</span><span class="n">Graph</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_t</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_index</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_s</span> <span class="o">=</span> <span class="n">x_s</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x_t</span> <span class="o">=</span> <span class="n">x_t</span>
</pre></div>
</div>
<p>For a correct mini-batching procedure in bipartite graphs,
we need to tell PyG that it should increment source and target nodes
of edges in <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index</span></code> independently on each other:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">__inc__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;edge_index&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tlx</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([[</span><span class="bp">self</span><span class="o">.</span><span class="n">x_s</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">x_t</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)]])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__inc__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>
</div>
<p>Here, <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index[0]</span></code> (the source nodes of edges) get incremented by <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_s.size(0)</span></code> while <code class="xref py py-obj docutils literal notranslate"><span class="pre">edge_index[1]</span></code> (the target nodes of edges)
get incremented by <code class="xref py py-obj docutils literal notranslate"><span class="pre">x_t.size(0)</span></code>.
We can again test our implementation by running a simple test script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gammagl.loader</span> <span class="kn">import</span> <span class="n">DataLoader</span>

 <span class="n">edge_index</span> <span class="o">=</span> <span class="n">tlx</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">([</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
 <span class="p">])</span>
 <span class="n">x_s</span> <span class="o">=</span> <span class="n">tlx</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>  <span class="c1"># 2 nodes.</span>
 <span class="n">x_t</span> <span class="o">=</span> <span class="n">tlx</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>  <span class="c1"># 3 nodes.</span>

 <span class="n">graph</span> <span class="o">=</span> <span class="n">BipartiteGraph</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x_s</span><span class="p">,</span> <span class="n">x_t</span><span class="p">)</span>
 <span class="n">Graph_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">graph</span><span class="p">,</span> <span class="n">graph</span><span class="p">]</span>
 <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">Graph_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
 <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>

 <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
 <span class="o">&gt;&gt;&gt;</span> <span class="n">BipartiteGraphBatch</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">x_s</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">x_t</span><span class="o">=</span><span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>

 <span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span>
 <span class="o">&gt;&gt;&gt;</span> <span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
             <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
</pre></div>
</div>
<p>Again, this is exactly the behaviour we aimed for!</p>
</section>
<section id="batching-along-new-dimensions">
<h2>Batching Along New Dimensions<a class="headerlink" href="#batching-along-new-dimensions" title="此标题的永久链接">¶</a></h2>
<p>Sometimes, attributes of <code class="xref py py-obj docutils literal notranslate"><span class="pre">Graph</span></code> objects should be batched by gaining a new batch dimension (as in classical mini-batching),
<em>e.g.</em>, for graph-level properties or targets.
Specifically, a list of attributes of shape <code class="xref py py-obj docutils literal notranslate"><span class="pre">[num_features]</span></code> should be returned as <code class="xref py py-obj docutils literal notranslate"><span class="pre">[num_examples,</span> <span class="pre">num_features]</span></code> rather
than <code class="xref py py-obj docutils literal notranslate"><span class="pre">[num_examples</span> <span class="pre">*</span> <span class="pre">num_features]</span></code>.
PyG achieves this by returning a concatenation dimension of <code class="xref py py-obj docutils literal notranslate"><span class="pre">None</span></code> in <code class="xref py py-meth docutils literal notranslate"><span class="pre">gammagl.data.Graph.__cat_dim__()</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gammagl.data</span> <span class="kn">import</span> <span class="n">Graph</span>
<span class="kn">from</span> <span class="nn">gammagl.loader</span> <span class="kn">import</span> <span class="n">GraphLoader</span>

 <span class="k">class</span> <span class="nc">MyGraph</span><span class="p">(</span><span class="n">Graph</span><span class="p">):</span>
     <span class="k">def</span> <span class="nf">__cat_dim__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
         <span class="k">if</span> <span class="n">key</span> <span class="o">==</span> <span class="s1">&#39;foo&#39;</span><span class="p">:</span>
             <span class="k">return</span> <span class="kc">None</span>
         <span class="k">else</span><span class="p">:</span>
             <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__cat_dim__</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="n">edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
   <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="p">])</span>
<span class="n">foo</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span>

<span class="n">graph</span> <span class="o">=</span> <span class="n">MyGraph</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">foo</span><span class="o">=</span><span class="n">foo</span><span class="p">)</span>
<span class="n">Graph_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">graph</span><span class="p">,</span> <span class="n">graph</span><span class="p">]</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">Graph_list</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">MyGraphBatch</span><span class="p">(</span><span class="n">edge_index</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">foo</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
</pre></div>
</div>
<p>As desired, <code class="xref py py-obj docutils literal notranslate"><span class="pre">batch.foo</span></code> is now described by two dimensions: The batch dimension and the feature dimension.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="create_gnn.html" class="btn btn-neutral float-left" title="Creating Message Passing Networks" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../api/gammagl.datasets.html" class="btn btn-neutral float-right" title="gammagl.datasets" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Jinyu Yang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>