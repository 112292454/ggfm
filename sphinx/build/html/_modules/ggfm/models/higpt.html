

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ggfm.models.higpt &mdash; GGFM 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=e031e9a9"></script>
      <script src="../../../_static/doctools.js?v=888ff710"></script>
      <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            GGFM
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/install.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/developer_guide.html">Developer Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.data.html">ggfm.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.conv.html">ggfm.conv</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.models.html">ggfm.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.evaluate.html">ggfm.evaluation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">GGFM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">ggfm.models.higpt</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ggfm.models.higpt</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">html</span>
<span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span>
<span class="kn">from</span> <span class="nn">omegaconf</span> <span class="kn">import</span> <span class="n">OmegaConf</span>
<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlparse</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch_geometric.typing</span> <span class="kn">import</span> <span class="n">Adj</span><span class="p">,</span> <span class="n">EdgeType</span><span class="p">,</span> <span class="n">NodeType</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span> <span class="n">Parameter</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>

<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AutoConfig</span><span class="p">,</span>
    <span class="n">AutoModel</span><span class="p">,</span>
    <span class="n">AutoModelForCausalLM</span><span class="p">,</span>
    <span class="n">AutoTokenizer</span><span class="p">,</span>
    <span class="n">LlamaTokenizer</span><span class="p">,</span>
    <span class="n">LlamaForCausalLM</span><span class="p">,</span>
    <span class="n">LlamaModel</span><span class="p">,</span>
    <span class="n">LlamaConfig</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">transformers.modeling_outputs</span> <span class="kn">import</span> <span class="n">BaseModelOutputWithPast</span><span class="p">,</span> <span class="n">CausalLMOutputWithPast</span>
<span class="kn">from</span> <span class="nn">transformers.configuration_utils</span> <span class="kn">import</span> <span class="n">PretrainedConfig</span>

<span class="kn">import</span> <span class="nn">torch_geometric</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn.conv</span> <span class="kn">import</span> <span class="n">MessagePassing</span>
<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="kn">from</span> <span class="nn">torch_geometric.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">remove_self_loops</span><span class="p">,</span>
    <span class="n">add_self_loops</span><span class="p">,</span>
    <span class="n">degree</span><span class="p">,</span>
    <span class="n">softmax</span><span class="p">,</span>
    <span class="n">add_remaining_self_loops</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch_geometric.utils.hetero</span> <span class="kn">import</span> <span class="n">construct_bipartite_edge_index</span>
<span class="c1"># from torch_scatter import scatter_add</span>

<span class="kn">import</span> <span class="nn">ftfy</span>


<span class="sd">&quot;&quot;&quot;Special tokens used in the model&quot;&quot;&quot;</span>
<span class="n">DEFAULT_GRAPH_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;graph&gt;&quot;</span>
<span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;g_patch&gt;&quot;</span>
<span class="n">DEFAULT_G_START_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;g_start&gt;&quot;</span>
<span class="n">DEFAULT_G_END_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;g_end&gt;&quot;</span>
<span class="n">IGNORE_INDEX</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
<span class="n">DEFAULT_PAD_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;[PAD]&quot;</span>
<span class="n">DEFAULT_EOS_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;/s&gt;&quot;</span>
<span class="n">DEFAULT_BOS_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;s&gt;&quot;</span>
<span class="n">DEFAULT_UNK_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;unk&gt;&quot;</span>

<span class="k">def</span> <span class="nf">is_url</span><span class="p">(</span><span class="n">url_or_filename</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if a string is a URL.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        url_or_filename (str): String to check</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        bool: True if string is a URL, False otherwise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parsed</span> <span class="o">=</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">url_or_filename</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">parsed</span><span class="o">.</span><span class="n">scheme</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;http&quot;</span><span class="p">,</span> <span class="s2">&quot;https&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_abs_path</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get absolute path from a potentially relative path.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        path (str): Input path</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        str: Absolute path</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>

<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">default_bpe</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get default path to BPE vocabulary file.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        str: Path to BPE vocabulary file</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)),</span> <span class="s2">&quot;bpe_simple_vocab_16e6.txt.gz&quot;</span><span class="p">)</span>

<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">bytes_to_unicode</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert bytes to unicode characters.</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">        dict: Mapping from bytes to unicode characters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;!&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;~&quot;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;¡&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;¬&quot;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;®&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;ÿ&quot;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">bs</span><span class="p">[:]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bs</span><span class="p">:</span>
            <span class="n">bs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="n">cs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="o">+</span><span class="n">n</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">cs</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get all adjacent pairs of characters from a word.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        word (tuple): Word as tuple of characters</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        set: Set of character pairs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">prev_char</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">pairs</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">prev_char</span><span class="p">,</span> <span class="n">char</span><span class="p">))</span>
        <span class="n">prev_char</span> <span class="o">=</span> <span class="n">char</span>
    <span class="k">return</span> <span class="n">pairs</span>

<span class="k">def</span> <span class="nf">basic_clean</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic text cleaning using ftfy.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        text (str): Input text</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        str: Cleaned text</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">ftfy</span><span class="o">.</span><span class="n">fix_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">html</span><span class="o">.</span><span class="n">unescape</span><span class="p">(</span><span class="n">html</span><span class="o">.</span><span class="n">unescape</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">whitespace_clean</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Clean whitespace in text.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        text (str): Input text</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        str: Text with normalized whitespace</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>

<span class="k">class</span> <span class="nc">BaseModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for all models in HiGPT.</span>
<span class="sd">    </span>
<span class="sd">    Provides common functionality for model loading, optimization and evaluation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the base model.&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the device where model parameters are stored.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>

    <span class="k">def</span> <span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">url_or_filename</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load model weights from a checkpoint file.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            url_or_filename (str): Path or URL to checkpoint</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            LoaderOutput: Results of loading the checkpoint</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_url</span><span class="p">(</span><span class="n">url_or_filename</span><span class="p">):</span>
            <span class="n">cached_file</span> <span class="o">=</span> <span class="n">download_cached_file</span><span class="p">(</span>
                <span class="n">url_or_filename</span><span class="p">,</span> <span class="n">check_hash</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">cached_file</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">url_or_filename</span><span class="p">):</span>
            <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">url_or_filename</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;checkpoint url or path is invalid&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;model&quot;</span> <span class="ow">in</span> <span class="n">checkpoint</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;model&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">checkpoint</span>

        <span class="n">msg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Missing keys </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">missing_keys</span><span class="p">))</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;load checkpoint from </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">url_or_filename</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">msg</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model_type</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a model instance from pretrained weights.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            model_type (str): Type/name of the pretrained model</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            BaseModel: Model instance initialized with pretrained weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">model_cfg</span> <span class="o">=</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">default_config_path</span><span class="p">(</span><span class="n">model_type</span><span class="p">))</span><span class="o">.</span><span class="n">model</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">model_cfg</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">default_config_path</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">model_type</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the default configuration file path for a model type.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            model_type (str): Type/name of the model</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: Path to the configuration file</span>
<span class="sd">            </span>
<span class="sd">        Raises:</span>
<span class="sd">            AssertionError: If model_type is not recognized</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">model_type</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">PRETRAINED_MODEL_CONFIG_DICT</span><span class="p">,</span> <span class="s2">&quot;Unknown model type </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">get_abs_path</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">PRETRAINED_MODEL_CONFIG_DICT</span><span class="p">[</span><span class="n">model_type</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">load_checkpoint_from_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load checkpoint based on configuration.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            cfg (Config): Configuration object containing checkpoint paths</span>
<span class="sd">            **kwargs: Additional arguments for loading pretrained weights</span>
<span class="sd">            </span>
<span class="sd">        Raises:</span>
<span class="sd">            AssertionError: If required paths are missing in config</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">load_finetuned</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_finetuned&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">load_finetuned</span><span class="p">:</span>
            <span class="n">finetune_path</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;finetuned&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">assert</span> <span class="n">finetune_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Found load_finetuned is True, but finetune_path is None.&quot;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">url_or_filename</span><span class="o">=</span><span class="n">finetune_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">load_pretrained</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;load_pretrained&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">load_pretrained</span><span class="p">:</span>
                <span class="n">pretrain_path</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;pretrained&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">assert</span> <span class="s2">&quot;Found load_finetuned is False, but pretrain_path is None.&quot;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">load_from_pretrained</span><span class="p">(</span><span class="n">url_or_filename</span><span class="o">=</span><span class="n">pretrain_path</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">before_training</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">get_optimizer_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="n">lr_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get parameters for optimizer with proper weight decay settings.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            weight_decay (float): Weight decay factor</span>
<span class="sd">            lr_scale (float, optional): Learning rate scaling factor. Defaults to 1</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            list: List of parameter groups with optimization settings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p_wd</span><span class="p">,</span> <span class="n">p_non_wd</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="mi">2</span> <span class="ow">or</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">n</span> <span class="ow">or</span> <span class="s2">&quot;ln&quot;</span> <span class="ow">in</span> <span class="n">n</span> <span class="ow">or</span> <span class="s2">&quot;bn&quot;</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
                <span class="n">p_non_wd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">p_wd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">optim_params</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p_wd</span><span class="p">,</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">weight_decay</span><span class="p">,</span> <span class="s2">&quot;lr_scale&quot;</span><span class="p">:</span> <span class="n">lr_scale</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">p_non_wd</span><span class="p">,</span> <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;lr_scale&quot;</span><span class="p">:</span> <span class="n">lr_scale</span><span class="p">},</span>
        <span class="p">]</span>
        <span class="k">return</span> <span class="n">optim_params</span>

    <span class="k">def</span> <span class="nf">before_evaluation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">show_n_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_str</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate and format the total number of parameters.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            return_str (bool, optional): Whether to return formatted string. Defaults to True</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Union[str, int]: Number of parameters as string (with M/K suffix) or integer</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tot</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">w</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="n">w</span> <span class="o">*=</span> <span class="n">x</span>
            <span class="n">tot</span> <span class="o">+=</span> <span class="n">w</span>
        <span class="k">if</span> <span class="n">return_str</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tot</span> <span class="o">&gt;=</span> <span class="mf">1e6</span><span class="p">:</span>
                <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{:.1f}</span><span class="s2">M&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tot</span> <span class="o">/</span> <span class="mf">1e6</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="s2">&quot;</span><span class="si">{:.1f}</span><span class="s2">K&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tot</span> <span class="o">/</span> <span class="mf">1e3</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tot</span>

<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Layer normalization module with fp16 support.</span>
<span class="sd">    </span>
<span class="sd">    Extends PyTorch&#39;s LayerNorm to properly handle float16 precision.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply layer normalization.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Normalized tensor in original dtype</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">orig_type</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">orig_type</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">QuickGELU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fast approximation of GELU activation function.</span>
<span class="sd">    </span>
<span class="sd">    Uses sigmoid multiplication instead of error function for efficiency.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply Quick GELU activation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Activated tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">1.702</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>
    
<span class="k">class</span> <span class="nc">graph_transformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Transformer model for processing graph structured data.</span>
<span class="sd">    </span>
<span class="sd">    Combines transformer architecture with graph neural network components</span>
<span class="sd">    to process graph node features and edge structure.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the graph transformer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            args: Configuration object containing model parameters including:</span>
<span class="sd">                - gnn_width: Width of GNN layers</span>
<span class="sd">                - gnn_layers: Number of GNN layers</span>
<span class="sd">                - gnn_heads: Number of attention heads</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
            <span class="n">width</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_width</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_layers</span><span class="p">,</span>
            <span class="n">heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_heads</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_post</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_width</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">)</span> <span class="o">/</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_width</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Process input graph through the transformer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            g: Graph object containing:</span>
<span class="sd">                - graph_node: Node feature tensor</span>
<span class="sd">                - edge_index: Edge connectivity tensor</span>
<span class="sd">                </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Processed node features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_node</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_post</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">proj</span>
            
        <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span>
    <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_gpus</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">max_gpu_memory</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">load_8bit</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">cpu_offloading</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a pretrained model from Hugging Face.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model_path (str): Path or name of model on HuggingFace</span>
<span class="sd">        device (str): Device to load model on (&#39;cpu&#39;, &#39;cuda&#39;, &#39;mps&#39;)</span>
<span class="sd">        num_gpus (int): Number of GPUs to use</span>
<span class="sd">        max_gpu_memory (str, optional): Maximum GPU memory per device</span>
<span class="sd">        load_8bit (bool, optional): Whether to load in 8-bit precision. Defaults to False</span>
<span class="sd">        cpu_offloading (bool, optional): Whether to offload weights to CPU. Defaults to False</span>
<span class="sd">        debug (bool, optional): Whether to print debug info. Defaults to False</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        AutoModelForCausalLM: Loaded model instance</span>
<span class="sd">        </span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If device is invalid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cpu&quot;</span><span class="p">:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">}</span>
    <span class="k">elif</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;torch_dtype&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">num_gpus</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;device_map&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>
            <span class="k">if</span> <span class="n">max_gpu_memory</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;device_map&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;sequential&quot;</span>
                <span class="n">available_gpu_memory</span> <span class="o">=</span> <span class="n">get_gpu_memory</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">)</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_memory&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="n">i</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">available_gpu_memory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.85</span><span class="p">))</span> <span class="o">+</span> <span class="s2">&quot;GiB&quot;</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">)</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;max_memory&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">max_gpu_memory</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">)}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_path</span><span class="p">,</span>
        <span class="n">low_cpu_mem_usage</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">and</span> <span class="n">num_gpus</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">cpu_offloading</span><span class="p">)</span> <span class="ow">or</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;mps&quot;</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">debug</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">add_model_args</span><span class="p">(</span><span class="n">parser</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Add model arguments to the parser.&quot;&quot;&quot;</span>
    <span class="n">group</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">add_argument_group</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--model-path&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;lmsys/vicuna-7b-v1.3&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to the model weights or model name on Hugging Face.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--device&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="s2">&quot;mps&quot;</span><span class="p">],</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The device to run the model on.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-gpus&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of GPUs to use.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--max-gpu-memory&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum GPU memory to use per GPU.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--load-8bit&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Load the model in 8-bit precision.&quot;</span>
    <span class="p">)</span>
    <span class="n">group</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--cpu-offloading&quot;</span><span class="p">,</span> 
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Offload model weights to CPU to save GPU memory.&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">group</span>

<span class="k">def</span> <span class="nf">get_gpu_memory</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get available memory for each GPU.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch.cuda</span>
    <span class="n">gpu_memory</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_gpus</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
            <span class="n">gpu_properties</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">total_memory</span> <span class="o">=</span> <span class="n">gpu_properties</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">)</span>  
            <span class="n">gpu_memory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">total_memory</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gpu_memory</span>

<span class="k">def</span> <span class="nf">maybe_zero_3</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">ignore_status</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Handle DeepSpeed ZeRO-3 params.&quot;&quot;&quot;</span>
    <span class="c1"># from deepspeed import zero</span>
    <span class="c1"># from deepspeed.runtime.zero.partition_parameters import ZeroParamStatus</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="s2">&quot;ds_id&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">ds_status</span> <span class="o">==</span> <span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">NOT_AVAILABLE</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">ignore_status</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: param.ds_status != ZeroParamStatus.NOT_AVAILABLE: </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">ds_status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">zero</span><span class="o">.</span><span class="n">GatheredParameters</span><span class="p">([</span><span class="n">param</span><span class="p">]):</span>
            <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">param</span>

<span class="k">class</span> <span class="nc">ResidualAttentionBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transformer block with residual attention and MLP.</span>
<span class="sd">    </span>
<span class="sd">    Implements a standard transformer block with self-attention followed by MLP,</span>
<span class="sd">    with layer normalization and residual connections.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_head</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">act_layer</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the residual attention block.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            d_model (int): Hidden dimension size</span>
<span class="sd">            n_head (int): Number of attention heads</span>
<span class="sd">            act_layer (Callable, optional): Activation function. Defaults to GELU</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">OrderedDict</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="p">(</span><span class="s2">&quot;c_fc&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)),</span>
                    <span class="p">(</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span> <span class="n">act_layer</span><span class="p">()),</span>
                    <span class="p">(</span><span class="s2">&quot;c_proj&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)),</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute self-attention.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor</span>
<span class="sd">            attn_mask (torch.Tensor, optional): Attention mask</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Self-attention output</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the block.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor</span>
<span class="sd">            attn_mask (torch.Tensor, optional): Attention mask</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Processed tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Full transformer model with multiple attention blocks.</span>
<span class="sd">    </span>
<span class="sd">    Stacks multiple ResidualAttentionBlocks to form a complete transformer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">act_layer</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the transformer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            width (int): Hidden dimension size</span>
<span class="sd">            layers (int): Number of transformer layers</span>
<span class="sd">            heads (int): Number of attention heads per layer</span>
<span class="sd">            act_layer (Callable, optional): Activation function. Defaults to GELU</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resblocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span>
            <span class="p">[</span><span class="n">ResidualAttentionBlock</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">act_layer</span><span class="o">=</span><span class="n">act_layer</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layers</span><span class="p">)]</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the transformer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (torch.Tensor): Input tensor</span>
<span class="sd">            attn_mask (torch.Tensor, optional): Attention mask</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Processed tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">resblocks</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">r</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="n">attn_mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="k">class</span> <span class="nc">SimpleTokenizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic tokenizer implementation with BPE encoding.</span>
<span class="sd">    </span>
<span class="sd">    Implements byte-pair encoding (BPE) tokenization with support for special tokens</span>
<span class="sd">    and caching.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bpe_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">default_bpe</span><span class="p">(),</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the tokenizer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            bpe_path (str, optional): Path to BPE vocabulary file</span>
<span class="sd">            special_tokens (list, optional): Additional special tokens to add</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">bpe_path</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="n">merges</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">49152</span><span class="o">-</span><span class="mi">256</span><span class="o">-</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">merge</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">merge</span> <span class="ow">in</span> <span class="n">merges</span><span class="p">]</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bytes_to_unicode</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span> <span class="o">+</span> <span class="p">[</span><span class="n">v</span><span class="o">+</span><span class="s1">&#39;&lt;/w&gt;&#39;</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">merge</span> <span class="ow">in</span> <span class="n">merges</span><span class="p">:</span>
            <span class="n">vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">merge</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">special_tokens</span><span class="p">:</span>
            <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;start_of_text&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;end_of_text&gt;&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">special_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;start_of_text&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;end_of_text&gt;&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">special_tokens</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">))))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="n">t</span><span class="p">:</span> <span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">}</span>
        <span class="n">special</span> <span class="o">=</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">special_tokens</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">special</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;|&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d|[\p</span><span class="si">{L}</span><span class="s2">]+|[\p</span><span class="si">{N}</span><span class="s2">]|[^\s\p</span><span class="si">{L}</span><span class="s2">\p</span><span class="si">{N}</span><span class="s2">]+&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_special_ids</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">special_tokens</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Apply byte-pair encoding to a token.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            token (str): Input token</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: BPE-encoded token</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="n">token</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;&lt;/w&gt;&quot;</span><span class="p">,)</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">token</span> <span class="o">+</span> <span class="s2">&quot;&lt;/w&gt;&quot;</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)))</span>
            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
                    <span class="k">break</span>

                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span><span class="o">+</span><span class="n">second</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
        <span class="k">return</span> <span class="n">word</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode text into token IDs.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            text (str): Input text</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            list: List of token IDs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bpe_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">whitespace_clean</span><span class="p">(</span><span class="n">basic_clean</span><span class="p">(</span><span class="n">text</span><span class="p">))</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
            <span class="n">token</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">))</span>
            <span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="n">bpe_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">bpe_tokens</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Decode token IDs back to text.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            tokens (list): List of token IDs</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: Decoded text</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">])</span>
        <span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;/w&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>

<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">texts</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">77</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize text(s) with special tokens and padding.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        texts (Union[str, List[str]]): Input text or list of texts</span>
<span class="sd">        context_length (int, optional): Maximum sequence length. Defaults to 77</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        torch.LongTensor: Tensor of token IDs with shape (batch_size, context_length)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">texts</span><span class="p">]</span>

    <span class="n">sot_token</span> <span class="o">=</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;&lt;start_of_text&gt;&quot;</span><span class="p">]</span>
    <span class="n">eot_token</span> <span class="o">=</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;&lt;end_of_text&gt;&quot;</span><span class="p">]</span>
    <span class="n">all_tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">sot_token</span><span class="p">]</span> <span class="o">+</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">eot_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">),</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">context_length</span><span class="p">:</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">context_length</span><span class="p">]</span>
        <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>

<span class="c1"># _tokenizer = SimpleTokenizer()</span>



<span class="k">def</span> <span class="nf">gcn_conv</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic Graph Convolutional Network convolution operation.</span>
<span class="sd">    </span>
<span class="sd">    Implements the standard GCN propagation rule with normalized adjacency matrix.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        h (torch.Tensor): Node feature matrix</span>
<span class="sd">        edge_index (torch.Tensor): Graph connectivity in COO format</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Updated node features after convolution</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">node_feas</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">remove_self_loops</span><span class="p">(</span><span class="n">edge_index</span><span class="p">)</span>
    <span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">add_self_loops</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
    
    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">edge_index</span>
    <span class="n">deg</span> <span class="o">=</span> <span class="n">degree</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>

    <span class="n">deg_src</span> <span class="o">=</span> <span class="n">deg</span><span class="p">[</span><span class="n">src</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> 
    <span class="n">deg_src</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">deg_src</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">deg_dst</span> <span class="o">=</span> <span class="n">deg</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">deg_dst</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">deg_dst</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">edge_weight</span> <span class="o">=</span> <span class="n">deg_src</span> <span class="o">*</span> <span class="n">deg_dst</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">]))</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
    <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">edge_index</span>
    <span class="n">edge_msg</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">edge_weight</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">col_embeds</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">cols</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">tem</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">node_feas</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">edge_msg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">rows</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">edge_msg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">h_prime</span> <span class="o">=</span> <span class="n">tem</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">edge_msg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">h_prime</span>

<span class="k">class</span> <span class="nc">MPNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Message Passing Neural Network implementation.</span>
<span class="sd">    </span>
<span class="sd">    A general framework for graph neural networks that updates node representations</span>
<span class="sd">    via message passing between neighbors.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        in_channels (int): Input feature dimension</span>
<span class="sd">        hidden_channels (int): Hidden layer dimension</span>
<span class="sd">        out_channels (int): Output feature dimension</span>
<span class="sd">        **kwargs: Additional arguments including:</span>
<span class="sd">            - dropout (float): Dropout rate</span>
<span class="sd">            - num_layers (int): Number of message passing layers</span>
<span class="sd">            - if_param (bool): Whether to use learnable parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MPNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dropout&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_layers&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;if_param&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize model parameters using Xavier initialization.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">mlp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.414</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">use_conv</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the MPNN.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            g: Graph object containing node features and connectivity</span>
<span class="sd">            use_conv (bool, optional): Whether to use convolution. Defaults to True</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Updated node features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_node</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span><span class="o">.</span><span class="fm">__next__</span><span class="p">()</span><span class="o">.</span><span class="n">device</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">use_conv</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">gcn_conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_conv</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">gcn_conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">MetaHGTConvCfg</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration class for Meta Heterogeneous Graph Transformer Convolution.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        in_channels (int): Input feature dimension</span>
<span class="sd">        out_channels (int): Output feature dimension</span>
<span class="sd">        heads (int): Number of attention heads</span>
<span class="sd">        dynamic (bool): Whether to use dynamic weight generation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">class</span> <span class="nc">MetaHGTConv</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Meta Heterogeneous Graph Transformer Convolution layer.</span>
<span class="sd">    </span>
<span class="sd">    Implements attention-based message passing for heterogeneous graphs with</span>
<span class="sd">    meta-learning capabilities for handling different types of nodes and edges.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">heads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">text_cfg</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize the MetaHGTConv layer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            in_channels (int): Input feature dimension</span>
<span class="sd">            out_channels (int): Output feature dimension</span>
<span class="sd">            heads (int, optional): Number of attention heads. Defaults to 1</span>
<span class="sd">            dynamic (bool, optional): Whether to use dynamic weights. Defaults to False</span>
<span class="sd">            text_cfg: Text processing configuration</span>
<span class="sd">            **kwargs: Additional arguments</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="n">node_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">out_channels</span> <span class="o">%</span> <span class="n">heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;out_channels&#39; (got </span><span class="si">{</span><span class="n">out_channels</span><span class="si">}</span><span class="s2">) must be divisible by the number of heads (got </span><span class="si">{</span><span class="n">heads</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">in_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">=</span> <span class="n">out_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">heads</span> <span class="o">=</span> <span class="n">heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">kqv_lin</span> <span class="o">=</span> <span class="n">MetaHeteroDictLinear</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span>
                                        <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">out_lin</span> <span class="o">=</span> <span class="n">MetaHeteroDictLinear</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="o">=</span> <span class="n">text_cfg</span><span class="o">.</span><span class="n">context_length</span>

        <span class="n">dim</span> <span class="o">=</span> <span class="n">out_channels</span> <span class="o">//</span> <span class="n">heads</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">k_rel</span> <span class="o">=</span> <span class="n">MetaHeteroLinear</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v_rel</span> <span class="o">=</span> <span class="n">MetaHeteroLinear</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">skipTrans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_relTrans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_cat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Concatenate features from different node types.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x_dict (Dict[str, Tensor]): Dictionary of node features by type</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Tensor, Dict[str, int]]: Concatenated features and offset mapping</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cumsum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">outs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">offset</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">outs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">offset</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumsum</span>
            <span class="n">cumsum</span> <span class="o">+=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">offset</span>

    <span class="k">def</span> <span class="nf">_construct_src_node_feat</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">k_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">v_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">edge_index_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="n">Adj</span><span class="p">],</span> 
        <span class="n">edge_type_feas_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> 
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct source node representations for attention.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            k_dict (Dict[str, Tensor]): Key vectors by node type</span>
<span class="sd">            v_dict (Dict[str, Tensor]): Value vectors by node type</span>
<span class="sd">            edge_index_dict (Dict[EdgeType, Adj]): Edge indices by type</span>
<span class="sd">            edge_type_feas_dict (Dict[EdgeType, Tensor]): Edge type features</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Tensor, Tensor, Dict[EdgeType, int]]: Processed key and value vectors with offsets</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cumsum</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">num_edge_types</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">edge_index_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">H</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span>

        <span class="n">ks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">vs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">type_list</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">offset</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">edge_types_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">edge_type</span><span class="p">:</span> <span class="n">i</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge_type</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">edge_index_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">edge_type</span> <span class="ow">in</span> <span class="n">edge_index_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">src</span> <span class="o">=</span> <span class="n">edge_type</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">N</span> <span class="o">=</span> <span class="n">k_dict</span><span class="p">[</span><span class="n">src</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">offset</span><span class="p">[</span><span class="n">edge_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">cumsum</span>
            <span class="n">cumsum</span> <span class="o">+=</span> <span class="n">N</span>

            <span class="n">edge_type_offset</span> <span class="o">=</span> <span class="n">edge_types_map</span><span class="p">[</span><span class="n">edge_type</span><span class="p">]</span>
            <span class="n">type_vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_edge_types</span> <span class="o">+</span> <span class="n">edge_type_offset</span>

            <span class="n">type_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">type_vec</span><span class="p">)</span>
            <span class="n">ks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k_dict</span><span class="p">[</span><span class="n">src</span><span class="p">])</span>
            <span class="n">vs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v_dict</span><span class="p">[</span><span class="n">src</span><span class="p">])</span>

        <span class="n">ks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="n">vs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">vs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="n">type_vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">type_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

        <span class="n">edge_feas_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">edge_types_map</span><span class="p">[</span><span class="n">k</span><span class="p">]:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">edge_type_feas_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">k_rel</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">type_vec</span><span class="p">,</span> <span class="n">edge_feas_dict</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_rel</span><span class="p">(</span><span class="n">vs</span><span class="p">,</span> <span class="n">type_vec</span><span class="p">,</span> <span class="n">edge_feas_dict</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">offset</span>

    <span class="k">def</span> <span class="nf">_construct_p_rel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge_type_feas_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct relation-specific attention weights.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            edge_type_feas_dict (Dict[EdgeType, Tensor]): Edge type features</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Dict[EdgeType, Tensor]: Processed attention weights for each edge type</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">p_rel</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_relTrans</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">edge_type_feas_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">p_rel</span>

    <span class="k">def</span> <span class="nf">_construct_skip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_type_feas_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Construct skip connection weights.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            node_type_feas_dict (Dict[EdgeType, Tensor]): Node type features</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Dict[EdgeType, Tensor]: Skip connection weights for each node type</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">skip</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">skipTrans</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">node_type_feas_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="k">return</span> <span class="n">skip</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">NodeType</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">edge_index_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="n">Adj</span><span class="p">],</span>
        <span class="n">data_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;dblp&#39;</span><span class="p">,</span>
        <span class="n">node_type_feas_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">NodeType</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">edge_type_feas_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">EdgeType</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">NodeType</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="n">F</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span>
        <span class="n">H</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">F</span> <span class="o">//</span> <span class="n">H</span>

        <span class="n">k_dict</span><span class="p">,</span> <span class="n">q_dict</span><span class="p">,</span> <span class="n">v_dict</span><span class="p">,</span> <span class="n">out_dict</span> <span class="o">=</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{},</span> <span class="p">{}</span>

        <span class="n">kqv_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kqv_lin</span><span class="p">(</span><span class="n">x_dict</span><span class="p">,</span> <span class="n">node_type_feas_dict</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">kqv_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">k_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
            <span class="n">q_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
            <span class="n">v_dict</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>

        <span class="n">q</span><span class="p">,</span> <span class="n">dst_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cat</span><span class="p">(</span><span class="n">q_dict</span><span class="p">)</span>
        <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">src_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_src_node_feat</span><span class="p">(</span>
            <span class="n">k_dict</span><span class="p">,</span> <span class="n">v_dict</span><span class="p">,</span> <span class="n">edge_index_dict</span><span class="p">,</span> <span class="n">edge_type_feas_dict</span><span class="p">)</span>
        <span class="n">p_rel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_p_rel</span><span class="p">(</span><span class="n">edge_type_feas_dict</span><span class="p">)</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_attr</span> <span class="o">=</span> <span class="n">construct_bipartite_edge_index</span><span class="p">(</span>
            <span class="n">edge_index_dict</span><span class="p">,</span> <span class="n">src_offset</span><span class="p">,</span> <span class="n">dst_offset</span><span class="p">,</span> <span class="n">edge_attr_dict</span><span class="o">=</span><span class="n">p_rel</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">edge_attr</span><span class="o">=</span><span class="n">edge_attr</span><span class="p">,</span>
                             <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">dst_node_types</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="n">key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">edge_index_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()])</span>

        <span class="k">for</span> <span class="n">node_type</span><span class="p">,</span> <span class="n">start_offset</span> <span class="ow">in</span> <span class="n">dst_offset</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">end_offset</span> <span class="o">=</span> <span class="n">start_offset</span> <span class="o">+</span> <span class="n">q_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">node_type</span> <span class="ow">in</span> <span class="n">dst_node_types</span><span class="p">:</span>
                <span class="n">out_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">start_offset</span><span class="p">:</span><span class="n">end_offset</span><span class="p">]</span>

        <span class="n">a_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_lin</span><span class="p">({</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">if</span> <span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">v</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">out_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">},</span> <span class="n">node_type_feas_dict</span><span class="p">)</span>

        <span class="n">skip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_construct_skip</span><span class="p">(</span><span class="n">node_type_feas_dict</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">node_type</span><span class="p">,</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">out_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">a_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">x_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">alpha</span> <span class="o">=</span> <span class="n">skip</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
                <span class="n">out</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">out</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>
            
        <span class="k">return</span> <span class="n">out_dict</span>

    <span class="k">def</span> <span class="nf">message</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k_j</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">q_i</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">v_j</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">edge_attr</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
                <span class="n">index</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">ptr</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
                <span class="n">size_i</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute messages in the message passing framework.</span>
<span class="sd">        </span>
<span class="sd">        Implements the attention-based message computation between nodes.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            k_j (Tensor): Key vectors of source nodes</span>
<span class="sd">            q_i (Tensor): Query vectors of target nodes</span>
<span class="sd">            v_j (Tensor): Value vectors of source nodes</span>
<span class="sd">            edge_attr (Tensor): Edge attributes</span>
<span class="sd">            index (Tensor): Target node indices</span>
<span class="sd">            ptr (Optional[Tensor]): Compressed sparse format pointer</span>
<span class="sd">            size_i (Optional[int]): Number of target nodes</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Computed messages</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="p">(</span><span class="n">q_i</span> <span class="o">*</span> <span class="n">k_j</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">edge_attr</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">q_i</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">size_i</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">v_j</span> <span class="o">*</span> <span class="n">alpha</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get string representation of the layer.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            str: Layer description with output channels and number of heads</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">(-1, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">out_channels</span><span class="si">}</span><span class="s1">, &#39;</span>
                <span class="sa">f</span><span class="s1">&#39;heads=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">heads</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Neural Network implementation.</span>
<span class="sd">    </span>
<span class="sd">    A basic GNN that uses message passing to update node representations.</span>
<span class="sd">    Includes learnable weight matrices and bias terms.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        args: Configuration object containing:</span>
<span class="sd">            - gnn_hid (int): Hidden dimension size</span>
<span class="sd">            - gnn_input (int): Input feature dimension</span>
<span class="sd">            - gnn_output (int): Output feature dimension</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>

        <span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_hid</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_input</span><span class="p">]))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_hid</span><span class="p">)))</span>

        <span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_hid</span><span class="p">]))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">)))</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">improved</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute normalized edge weights.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            edge_index (Tensor): Edge indices</span>
<span class="sd">            num_nodes (int): Number of nodes in graph</span>
<span class="sd">            improved (bool, optional): Whether to use improved normalization. Defaults to False</span>
<span class="sd">            dtype (torch.dtype, optional): Data type of weights</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Tensor, Tensor]: Normalized edge indices and weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">edge_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">edge_index</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                                 <span class="n">device</span><span class="o">=</span><span class="n">edge_index</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">fill_value</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">improved</span> <span class="k">else</span> <span class="mf">2.0</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_weight</span> <span class="o">=</span> <span class="n">add_remaining_self_loops</span><span class="p">(</span>
            <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>

        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="n">scatter_add</span><span class="p">(</span><span class="n">edge_weight</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">)</span>
        <span class="n">deg_inv_sqrt</span> <span class="o">=</span> <span class="n">deg</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">deg_inv_sqrt</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">*</span> <span class="n">edge_weight</span> <span class="o">*</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_node</span>
        <span class="k">if</span> <span class="nb">vars</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span>
        <span class="n">improved</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">),</span> <span class="n">improved</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">),</span> <span class="n">improved</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">CLIPTextCfg</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration class for CLIP text encoder.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        context_length (int): Maximum sequence length for text</span>
<span class="sd">        vocab_size (int): Size of vocabulary</span>
<span class="sd">        width (int): Hidden dimension size</span>
<span class="sd">        heads (int): Number of attention heads</span>
<span class="sd">        layers (int): Number of transformer layers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">width</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">layers</span><span class="p">:</span> <span class="nb">int</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ClipOutputFeatures</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data class for storing features extracted by CLIP model.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        image_embeds (torch.FloatTensor, optional): Raw image embeddings</span>
<span class="sd">        image_embeds_proj (torch.FloatTensor, optional): Projected image embeddings</span>
<span class="sd">        text_embeds (torch.FloatTensor, optional): Raw text embeddings</span>
<span class="sd">        text_embeds_proj (torch.FloatTensor, optional): Projected text embeddings</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">image_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">image_embeds_proj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">text_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">text_embeds_proj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">ClipOutput</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Output class for CLIP model.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        intermediate_output (ClipOutputFeatures, optional): Intermediate feature outputs</span>
<span class="sd">        logit_scale_exp (torch.FloatTensor, optional): Exponential of learnable temperature parameter</span>
<span class="sd">        loss (torch.FloatTensor, optional): Contrastive loss value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">intermediate_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ClipOutputFeatures</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">logit_scale_exp</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">loss</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">HeteClipOutputFeatures</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data class for storing features from heterogeneous CLIP model.</span>
<span class="sd">    </span>
<span class="sd">    Similar to ClipOutputFeatures but replaces image embeddings with graph embeddings</span>
<span class="sd">    for handling heterogeneous graph data.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        graph_embeds (torch.FloatTensor, optional): Raw graph embeddings</span>
<span class="sd">        graph_embeds_proj (torch.FloatTensor, optional): Projected graph embeddings</span>
<span class="sd">        text_embeds (torch.FloatTensor, optional): Raw text embeddings</span>
<span class="sd">        text_embeds_proj (torch.FloatTensor, optional): Projected text embeddings</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">graph_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">graph_embeds_proj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">text_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">text_embeds_proj</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">class</span> <span class="nc">CLIP</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CLIP model adapted for graph-text contrastive learning.</span>
<span class="sd">    </span>
<span class="sd">    Implements a CLIP-style architecture that learns joint embeddings of </span>
<span class="sd">    heterogeneous graphs and text descriptions.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        embed_dim (int): Joint embedding dimension</span>
<span class="sd">        graph_cfg (MetaHGTConvCfg): Configuration for graph encoder</span>
<span class="sd">        text_cfg (CLIPTextCfg): Configuration for text encoder</span>
<span class="sd">        quick_gelu (bool, optional): Whether to use quick GELU activation. Defaults to False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">embed_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">graph_cfg</span><span class="p">:</span> <span class="n">MetaHGTConvCfg</span><span class="p">,</span>
        <span class="n">text_cfg</span><span class="p">:</span> <span class="n">CLIPTextCfg</span><span class="p">,</span>
        <span class="n">quick_gelu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenize</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">graph_cfg</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">graph_cfg</span> <span class="o">=</span> <span class="n">MetaHGTConvCfg</span><span class="p">(</span><span class="o">**</span><span class="n">graph_cfg</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">text_cfg</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">text_cfg</span> <span class="o">=</span> <span class="n">CLIPTextCfg</span><span class="p">(</span><span class="o">**</span><span class="n">text_cfg</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="o">=</span> <span class="n">text_cfg</span><span class="o">.</span><span class="n">context_length</span>
        <span class="n">act_layer</span> <span class="o">=</span> <span class="n">QuickGELU</span> <span class="k">if</span> <span class="n">quick_gelu</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">graph_encoder</span> <span class="o">=</span> <span class="n">MetaHGTConv</span><span class="p">(</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="n">graph_cfg</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span>
            <span class="n">out_channels</span> <span class="o">=</span> <span class="n">graph_cfg</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
            <span class="n">heads</span> <span class="o">=</span> <span class="n">graph_cfg</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span>
            <span class="n">dynamic</span> <span class="o">=</span> <span class="n">graph_cfg</span><span class="o">.</span><span class="n">dynamic</span><span class="p">,</span>
            <span class="n">text_cfg</span> <span class="o">=</span> <span class="n">text_cfg</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
            <span class="n">width</span><span class="o">=</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">=</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span>
            <span class="n">heads</span><span class="o">=</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span>
            <span class="n">act_layer</span><span class="o">=</span><span class="n">act_layer</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">text_cfg</span><span class="o">.</span><span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_final</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">text_cfg</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mf">0.07</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;attn_mask&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">build_attention_mask</span><span class="p">(),</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_templates</span> <span class="o">=</span> <span class="n">openai_imagenet_template</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">init_parameters</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the contrastive loss function.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span> <span class="o">=</span> <span class="n">HeteClipLoss</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss</span>

    <span class="k">def</span> <span class="nf">init_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize model parameters with proper scaling.&quot;&quot;&quot;</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mf">0.07</span><span class="p">))</span>

        <span class="n">proj_std</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">attn_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="n">fc_std</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">resblocks</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">attn_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">proj_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">c_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">fc_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">c_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">proj_std</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">build_attention_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build causal attention mask for transformer.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Attention mask with upper triangular set to -inf</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">)</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">triu_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">encode_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">des_order</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode heterogeneous graph inputs.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            graph (List[Dict[str, torch.Tensor]]): List of graph dictionaries</span>
<span class="sd">            des_order (List[List[str]]): Node type ordering for each graph</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Graph embeddings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">graph_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">graph_dict</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">:</span>
            <span class="n">graph_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_encoder</span><span class="p">(</span><span class="n">graph_dict</span><span class="o">.</span><span class="n">x_dict</span><span class="p">,</span> <span class="n">graph_dict</span><span class="o">.</span><span class="n">edge_index_dict</span><span class="p">))</span>
        <span class="n">graph_embeds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">graph_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">des_order</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">des_order</span><span class="p">):</span>
            <span class="n">graph_embeds</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">graph_list</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">o</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">order</span><span class="p">])</span>
        <span class="n">graph_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">graph_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">graph_embeds</span>

    <span class="k">def</span> <span class="nf">encode_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encode text inputs through transformer.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            text: Input text tokens</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: Text embeddings</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_final</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">text</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass computing contrastive loss between graph and text.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            samples: Dictionary containing:</span>
<span class="sd">                - graph (List[Dict]): Graph inputs</span>
<span class="sd">                - text_input (List[str]): Text inputs</span>
<span class="sd">                - des_order (List[List[str]]): Node type ordering</span>
<span class="sd">                </span>
<span class="sd">        Returns:</span>
<span class="sd">            ClipOutput: Model outputs including features and loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">graph</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;graph&quot;</span><span class="p">)</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text_input&quot;</span><span class="p">)</span>
        <span class="n">des_order</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;des_order&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">graph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">des_order</span><span class="p">)</span>

        <span class="n">graph_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">des_order</span><span class="p">)</span>
        <span class="n">graph_features</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">graph_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">text_features</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">graph_features</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">text_features</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">graph_features</span><span class="p">,</span> <span class="n">text_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">ClipOutput</span><span class="p">(</span>
            <span class="n">intermediate_output</span><span class="o">=</span><span class="n">HeteClipOutputFeatures</span><span class="p">(</span>
                <span class="n">graph_embeds</span><span class="o">=</span><span class="n">graph_embeds</span><span class="p">,</span>
                <span class="n">graph_embeds_proj</span><span class="o">=</span><span class="n">graph_features</span><span class="p">,</span>
                <span class="n">text_embeds</span><span class="o">=</span><span class="n">text_embeds</span><span class="p">,</span>
                <span class="n">text_embeds_proj</span><span class="o">=</span><span class="n">text_features</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logit_scale_exp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">logit_scale</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">extract_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Extract features without computing loss.</span>
<span class="sd">        </span>
<span class="sd">        Similar to forward() but only returns embeddings without loss computation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            samples: Dictionary containing graph and text inputs</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            HeteClipOutputFeatures: Extracted features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">graph</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;graph&quot;</span><span class="p">)</span>
        <span class="n">text</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;text_input&quot;</span><span class="p">)</span>
        <span class="n">des_order</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="n">samples</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;des_order&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">text</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">graph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">text</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">des_order</span><span class="p">)</span>

        <span class="n">graph_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">des_order</span><span class="p">)</span>
        <span class="n">graph_features</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">graph_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">text_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="n">text_features</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">text_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">graph_features</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">text_features</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">return</span> <span class="n">HeteClipOutputFeatures</span><span class="p">(</span>
            <span class="n">graph_embeds</span><span class="o">=</span><span class="n">graph_embeds</span><span class="p">,</span>
            <span class="n">graph_embeds_proj</span><span class="o">=</span><span class="n">graph_features</span><span class="p">,</span>
            <span class="n">text_embeds</span><span class="o">=</span><span class="n">text_embeds</span><span class="p">,</span>
            <span class="n">text_embeds_proj</span><span class="o">=</span><span class="n">text_features</span><span class="p">,</span>
        <span class="p">)</span>



<span class="k">class</span> <span class="nc">GraphLlamaConfig</span><span class="p">(</span><span class="n">LlamaConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration class for GraphLLaMA model.</span>
<span class="sd">    </span>
<span class="sd">    Extends LlamaConfig to include graph-specific configuration options.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;GraphLlama&quot;</span>

<span class="k">class</span> <span class="nc">GraphPretrainConfig</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration class for graph pre-training.</span>
<span class="sd">    </span>
<span class="sd">    A simple wrapper that converts dictionary config to object attributes.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        dictionary (dict): Configuration dictionary</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_model_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrain_model_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a pretrained model from checkpoint.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model_name: Model class to instantiate</span>
<span class="sd">        pretrain_model_path (str): Path to pretrained model checkpoint</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        Tuple[nn.Module, GraphPretrainConfig]: Loaded model and its configuration</span>
<span class="sd">        </span>
<span class="sd">    Raises:</span>
<span class="sd">        AssertionError: If config.json is missing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;config.json&#39;</span><span class="p">)),</span> <span class="s1">&#39;config.json missing&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">GraphPretrainConfig</span><span class="p">(</span><span class="n">config_dict</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_name</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">pkl_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;*.pkl&#39;</span><span class="p">))</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pkl_files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="s1">&#39;logit_scale&#39;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;logit_scale&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loading graph pre train model&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">args</span>

<span class="k">def</span> <span class="nf">load_metahgt_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrain_model_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load a pretrained MetaHGT model from checkpoint.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model_name: Should be MetaHGTConv class</span>
<span class="sd">        pretrain_model_path (str): Path to pretrained model checkpoint</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        MetaHGTConv: Loaded model instance</span>
<span class="sd">        </span>
<span class="sd">    Raises:</span>
<span class="sd">        AssertionError: If config files are missing or model_name is incorrect</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;graph_config.json&#39;</span><span class="p">)),</span> <span class="s1">&#39;graph_config.json missing&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;graph_config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">graph_config_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">graph_cfg</span> <span class="o">=</span> <span class="n">MetaHGTConvCfg</span><span class="p">(</span><span class="o">**</span><span class="n">graph_config_dict</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;text_config.json&#39;</span><span class="p">)),</span> <span class="s1">&#39;text_config.json missing&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;text_config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">text_config_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">text_cfg</span> <span class="o">=</span> <span class="n">CLIPTextCfg</span><span class="p">(</span><span class="o">**</span><span class="n">text_config_dict</span><span class="p">)</span>
    
    <span class="k">assert</span> <span class="n">model_name</span> <span class="o">==</span> <span class="n">MetaHGTConv</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_name</span><span class="p">(</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">graph_cfg</span><span class="o">.</span><span class="n">in_channels</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">graph_cfg</span><span class="o">.</span><span class="n">out_channels</span><span class="p">,</span>
        <span class="n">heads</span><span class="o">=</span><span class="n">graph_cfg</span><span class="o">.</span><span class="n">heads</span><span class="p">,</span>
        <span class="n">dynamic</span><span class="o">=</span><span class="n">graph_cfg</span><span class="o">.</span><span class="n">dynamic</span><span class="p">,</span>
        <span class="n">text_cfg</span><span class="o">=</span><span class="n">text_cfg</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">pkl_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;*.ckpt&#39;</span><span class="p">))</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pkl_files</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)[</span><span class="s1">&#39;state_dict&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loading graph pre train model ...&#39;</span><span class="p">)</span>
    <span class="n">gnn_state_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;model.graph_encoder&#39;</span><span class="p">):</span>
            <span class="n">new_key</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;model.graph_encoder.&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">gnn_state_dict</span><span class="p">[</span><span class="n">new_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">gnn_state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">gnn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transfer parameters from CLIP graph encoder to GNN.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        clip_graph: Source CLIP model containing graph encoder</span>
<span class="sd">        gnn: Target GNN model</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        nn.Module: GNN with transferred parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">gnn_state_dict</span> <span class="o">=</span> <span class="n">clip_graph</span><span class="o">.</span><span class="n">gnn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">gnn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">gnn_state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gnn</span>

<span class="k">class</span> <span class="nc">GraphLlamaModel</span><span class="p">(</span><span class="n">LlamaModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    GraphLLaMA model that combines LLaMA with graph processing capabilities.</span>
<span class="sd">    </span>
<span class="sd">    Extends LlamaModel to handle graph inputs through various graph neural network</span>
<span class="sd">    architectures including MPNN, GCN, and graph transformers.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        config (LlamaConfig): Model configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">GraphLlamaConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">LlamaConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphLlamaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;graph_tower&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s1">&#39;MPNN&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">MPNN</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">if_param</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gcn_arxiv&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv_pub&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_graph_proj&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_graph_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the graph processing component.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            nn.Module: Graph neural network module</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">graph_tower</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_tower&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_tower</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">graph_tower</span>

    <span class="k">def</span> <span class="nf">initialize_graph_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">,</span> <span class="n">graph_select_layer</span><span class="p">,</span>
                               <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fsdp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize graph processing modules.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            graph_tower (str): Type of graph neural network to use</span>
<span class="sd">            graph_select_layer (int): Which layer to select features from</span>
<span class="sd">            pretrain_graph_mlp_adapter (str, optional): Path to pretrained adapter weights</span>
<span class="sd">            fsdp (list, optional): FSDP configuration</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_tower&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s1">&#39;MPNN&#39;</span><span class="p">:</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">MPNN</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">hidden_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">if_param</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gcn_arxiv&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv_pub&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span>

        <span class="n">graph_tower</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fsdp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">fsdp</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="p">[</span><span class="n">graph_tower</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_proj</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_select_layer</span> <span class="o">=</span> <span class="n">graph_select_layer</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_projector&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pretrain_graph_mlp_adapter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">graph_projector_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span><span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">graph_projector_weights</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">graph_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Data</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">BaseModelOutputWithPast</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the GraphLLaMA model.</span>
<span class="sd">        </span>
<span class="sd">        Processes both text and graph inputs through the model, combining them</span>
<span class="sd">        via graph-augmented attention mechanisms.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            input_ids (torch.LongTensor, optional): Input token IDs</span>
<span class="sd">            attention_mask (torch.Tensor, optional): Attention mask</span>
<span class="sd">            past_key_values (List[torch.FloatTensor], optional): Cached key/values for faster inference</span>
<span class="sd">            inputs_embeds (torch.FloatTensor, optional): Pre-computed input embeddings</span>
<span class="sd">            use_cache (bool, optional): Whether to use past key/values</span>
<span class="sd">            output_attentions (bool, optional): Whether to output attention weights</span>
<span class="sd">            output_hidden_states (bool, optional): Whether to output all hidden states</span>
<span class="sd">            graph_data (Data, optional): Input graph data</span>
<span class="sd">            return_dict (bool, optional): Whether to return a dictionary output</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Union[Tuple, BaseModelOutputWithPast]: Model outputs including hidden states,</span>
<span class="sd">                attention weights and past key/values if requested</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">orig_embeds_params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;orig_embeds_params&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inputs_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_tokens</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">graph_tower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">graph_tower</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span> <span class="ow">and</span> <span class="n">graph_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                    <span class="n">graph_node_features</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="n">Data</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">graph_data</span><span class="p">:</span>
                            <span class="n">node_forward_out</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">g_dict</span> <span class="ow">in</span> <span class="n">graph_data</span><span class="p">:</span>
                            <span class="n">node_forward_out_1</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g_dict</span><span class="p">[</span><span class="s1">&#39;graph_1&#39;</span><span class="p">])</span>
                            <span class="n">node_forward_out_2</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g_dict</span><span class="p">[</span><span class="s1">&#39;graph_2&#39;</span><span class="p">])</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out_1</span><span class="p">)</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out_2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;graph_node_reps is expected to be a list but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                <span class="n">graph_node_features</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="p">(</span><span class="n">node_feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">node_feature</span> <span class="ow">in</span> <span class="n">graph_node_features</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;graph_node_reps is expected to be a list but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="n">dummy_graph_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">dummy_graph_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="p">(</span><span class="n">dummy_graph_features</span><span class="p">)</span>

            <span class="n">new_input_embeds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">cur_graph_idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">cur_input_ids</span><span class="p">,</span> <span class="n">cur_input_embeds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">cur_input_embeds</span> <span class="o">=</span> <span class="n">cur_input_embeds</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.</span> <span class="o">*</span> <span class="n">dummy_graph_features</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_input_embeds</span><span class="p">)</span>
                    <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_start_end</span><span class="p">:</span>
                    <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span>
                    <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_end_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of graph start tokens and graph end tokens should be the same.&quot;</span><span class="p">)</span>
                    <span class="n">graph_start_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">graph_start_token_pos</span> <span class="ow">in</span> <span class="n">graph_start_tokens</span><span class="p">:</span>
                        <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">cur_input_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                        <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="k">if</span> <span class="n">cur_input_ids</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_end_token</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The graph end token should follow the graph start token.&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">orig_embeds_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">graph_start_token_pos</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span><span class="p">:</span><span class="n">graph_start_token_pos</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">graph_start_token_pos</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_new_input_embeds</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span>
                    <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="n">num_patches</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of graph patch tokens should be the same as the number of graph patches.&quot;</span><span class="p">)</span>
                    <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">mask_index_start</span> <span class="o">=</span> <span class="n">masked_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">masked_indices</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">mask_index_start</span><span class="p">,</span> <span class="n">mask_index_start</span><span class="o">+</span><span class="n">num_patches</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">masked_indices</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">masked_indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The graph patch tokens should be consecutive.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">orig_embeds_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">mask_index_start</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">mask_index_start</span><span class="o">+</span><span class="n">num_patches</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">mask_index_start</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">mask_index_start</span><span class="o">+</span><span class="n">num_patches</span><span class="p">:]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_new_input_embeds</span><span class="p">)</span>
                    <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">assert</span> <span class="n">cur_graph_idx</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">graph_node_features</span><span class="p">)</span>
            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_input_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">GraphLlamaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span>
        <span class="p">)</span>

<span class="k">class</span> <span class="nc">GraphLlamaForCausalLM</span><span class="p">(</span><span class="n">LlamaForCausalLM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    GraphLLaMA model for causal language modeling.</span>
<span class="sd">    </span>
<span class="sd">    Extends LlamaForCausalLM to support graph-augmented language modeling by</span>
<span class="sd">    incorporating graph structure information into the generation process.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        config (GraphLlamaConfig): Model configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">GraphLlamaConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LlamaForCausalLM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GraphLlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the underlying GraphLlamaModel.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span>

    <span class="k">def</span> <span class="nf">get_graph_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the graph processing component.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">graph_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Data</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CausalLMOutputWithPast</span><span class="p">]:</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="n">graph_data</span><span class="o">=</span><span class="n">graph_data</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">shift_logits</span><span class="p">,</span> <span class="n">shift_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">CausalLMOutputWithPast</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">prepare_inputs_for_generation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prepare inputs for text generation.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            input_ids: Input token IDs</span>
<span class="sd">            past_key_values: Cached key/values from previous forward passes</span>
<span class="sd">            attention_mask: Attention mask</span>
<span class="sd">            inputs_embeds: Pre-computed input embeddings</span>
<span class="sd">            **kwargs: Additional arguments</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            dict: Dictionary of model inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">past_key_values</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">if</span> <span class="n">inputs_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs_embeds&quot;</span><span class="p">:</span> <span class="n">inputs_embeds</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">}</span>

        <span class="n">model_inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
                <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
                <span class="s2">&quot;graph_data&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;graph_data&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">model_inputs</span>

    <span class="k">def</span> <span class="nf">initialize_graph_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_graph_start_end</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
                                 <span class="n">tune_graph_mlp_adapter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize tokenizer for graph inputs.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            use_graph_start_end (bool): Whether to use special graph tokens</span>
<span class="sd">            tokenizer: Base tokenizer to extend</span>
<span class="sd">            device: Device to place new tokens on</span>
<span class="sd">            tune_graph_mlp_adapter (bool): Whether to tune graph MLP adapter</span>
<span class="sd">            pretrain_graph_mlp_adapter (str, optional): Path to pretrained adapter</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span><span class="o">.</span><span class="n">config</span>
        <span class="n">vision_config</span><span class="o">.</span><span class="n">use_graph_start_end</span> <span class="o">=</span> <span class="n">use_graph_start_end</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span><span class="p">],</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">use_graph_start_end</span><span class="p">:</span>
            <span class="n">num_new_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="n">DEFAULT_G_START_TOKEN</span><span class="p">,</span> <span class="n">DEFAULT_G_END_TOKEN</span><span class="p">],</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
            <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">,</span> <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_end_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">([</span><span class="n">DEFAULT_G_START_TOKEN</span><span class="p">,</span> <span class="n">DEFAULT_G_END_TOKEN</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">num_new_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">input_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
                <span class="n">output_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>

                <span class="n">input_embeddings_avg</span> <span class="o">=</span> <span class="n">input_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">output_embeddings_avg</span> <span class="o">=</span> <span class="n">output_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">input_embeddings_avg</span>
                <span class="n">output_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">output_embeddings_avg</span>

            <span class="k">if</span> <span class="n">tune_graph_mlp_adapter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">orig_embeds_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)]</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">pretrain_graph_mlp_adapter</span><span class="p">:</span>
                <span class="n">mm_projector_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                <span class="n">embed_tokens_weight</span> <span class="o">=</span> <span class="n">mm_projector_weights</span><span class="p">[</span><span class="s1">&#39;model.embed_tokens.weight&#39;</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">num_new_tokens</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                    <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">embed_tokens_weight</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span>
                <span class="k">elif</span> <span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_new_tokens</span><span class="p">:</span>
                    <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">embed_tokens_weight</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected embed_tokens_weight shape. Pretrained: </span><span class="si">{</span><span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Current: </span><span class="si">{</span><span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Numer of new tokens: </span><span class="si">{</span><span class="n">num_new_tokens</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_patch_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">([</span><span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>


<span class="n">AutoConfig</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;GraphLlama&quot;</span><span class="p">,</span> <span class="n">GraphLlamaConfig</span><span class="p">)</span>
<span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">GraphLlamaConfig</span><span class="p">,</span> <span class="n">GraphLlamaForCausalLM</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">HeteroLlamaConfig</span><span class="p">(</span><span class="n">LlamaConfig</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configuration class for HeteroLLaMA model.</span>
<span class="sd">    </span>
<span class="sd">    Extends LlamaConfig to include configuration options for heterogeneous graph processing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;HeteroLlama&quot;</span>

<span class="k">class</span> <span class="nc">HeteroLlamaModel</span><span class="p">(</span><span class="n">LlamaModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    HeteroLLaMA model that handles heterogeneous graph inputs.</span>
<span class="sd">    </span>
<span class="sd">    Extends LlamaModel to process heterogeneous graphs with different node and edge types</span>
<span class="sd">    through specialized graph neural networks.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        config (LlamaConfig): Model configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">HeteroLlamaConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">LlamaConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HeteroLlamaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;graph_tower&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s1">&#39;MPNN&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">MPNN</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">if_param</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;meta_hgt&quot;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">load_metahgt_pretrained</span><span class="p">(</span><span class="n">MetaHGTConv</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_graph_proj&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_graph_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">graph_tower</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_tower&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_tower</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">graph_tower</span>

    <span class="k">def</span> <span class="nf">initialize_graph_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">,</span> <span class="n">graph_select_layer</span><span class="p">,</span>
                               <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fsdp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_tower&#39;</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s1">&#39;MPNN&#39;</span><span class="p">:</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">MPNN</span><span class="p">(</span>
                    <span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">hidden_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">if_param</span><span class="o">=</span><span class="kc">False</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;meta_hgt&quot;</span><span class="p">:</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">load_metahgt_pretrained</span><span class="p">(</span><span class="n">MetaHGTConv</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span>

        <span class="n">graph_tower</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fsdp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">fsdp</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="p">[</span><span class="n">graph_tower</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_proj</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_select_layer</span> <span class="o">=</span> <span class="n">graph_select_layer</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_projector&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pretrain_graph_mlp_adapter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">graph_projector_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span><span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">graph_projector_weights</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">graph_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Data</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hetero_key_order</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">BaseModelOutputWithPast</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the HeteroLLaMA model.</span>
<span class="sd">        </span>
<span class="sd">        Processes heterogeneous graph inputs along with text through the model.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            input_ids (torch.LongTensor, optional): Input token IDs</span>
<span class="sd">            attention_mask (torch.Tensor, optional): Attention mask</span>
<span class="sd">            past_key_values (List[torch.FloatTensor], optional): Cached key/values</span>
<span class="sd">            inputs_embeds (torch.FloatTensor, optional): Pre-computed input embeddings</span>
<span class="sd">            use_cache (bool, optional): Whether to use past key/values</span>
<span class="sd">            output_attentions (bool, optional): Whether to output attention weights</span>
<span class="sd">            output_hidden_states (bool, optional): Whether to output all hidden states</span>
<span class="sd">            graph_data (Data, optional): Input heterogeneous graph data</span>
<span class="sd">            return_dict (bool, optional): Whether to return a dictionary output</span>
<span class="sd">            hetero_key_order (List[List[str]], optional): Node type ordering for heterogeneous graphs</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Union[Tuple, BaseModelOutputWithPast]: Model outputs including hidden states,</span>
<span class="sd">                attention weights and past key/values if requested</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">orig_embeds_params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;orig_embeds_params&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">inputs_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_tokens</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">graph_tower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">graph_tower</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span> <span class="ow">and</span> <span class="n">graph_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                    <span class="n">graph_node_features</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="n">Data</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">graph_data</span><span class="p">:</span>
                            <span class="n">node_forward_out</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">x_dict</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index_dict</span><span class="p">)</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">g_dict</span> <span class="ow">in</span> <span class="n">graph_data</span><span class="p">:</span>
                            <span class="n">node_forward_out_1</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g_dict</span><span class="p">[</span><span class="s1">&#39;graph_1&#39;</span><span class="p">])</span>
                            <span class="n">node_forward_out_2</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g_dict</span><span class="p">[</span><span class="s1">&#39;graph_2&#39;</span><span class="p">])</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out_1</span><span class="p">)</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out_2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;graph_node_reps is expected to be a list but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                <span class="n">graph_node_features_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hetero_key_order</span><span class="p">):</span>
                    <span class="n">graph_node_features_list</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">graph_node_features</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">o</span><span class="p">]</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">order</span><span class="p">])</span>
                <span class="n">graph_node_features</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="p">(</span><span class="n">node_feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">node_feature</span> <span class="ow">in</span> <span class="n">graph_node_features_list</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;graph_node_reps is expected to be a list but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

            <span class="n">dummy_graph_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">dummy_graph_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="p">(</span><span class="n">dummy_graph_features</span><span class="p">)</span>

            <span class="n">new_input_embeds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">cur_graph_idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">cur_input_ids</span><span class="p">,</span> <span class="n">cur_input_embeds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">cur_input_embeds</span> <span class="o">=</span> <span class="n">cur_input_embeds</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.</span> <span class="o">*</span> <span class="n">dummy_graph_features</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_input_embeds</span><span class="p">)</span>
                    <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_start_end</span><span class="p">:</span>
                    <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span>
                    <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_end_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of graph start tokens and graph end tokens should be the same.&quot;</span><span class="p">)</span>
                    <span class="n">graph_start_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">graph_start_token_pos</span> <span class="ow">in</span> <span class="n">graph_start_tokens</span><span class="p">:</span>
                        <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">cur_input_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                        <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="k">if</span> <span class="n">cur_input_ids</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_end_token</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The graph end token should follow the graph start token.&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">orig_embeds_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">graph_start_token_pos</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span><span class="p">:</span><span class="n">graph_start_token_pos</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">graph_start_token_pos</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_new_input_embeds</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span>
                    <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="n">num_patches</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of graph patch tokens should be the same as the number of graph patches.&quot;</span><span class="p">)</span>
                    <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">mask_index_start</span> <span class="o">=</span> <span class="n">masked_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">masked_indices</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">mask_index_start</span><span class="p">,</span> <span class="n">mask_index_start</span><span class="o">+</span><span class="n">num_patches</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">masked_indices</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">masked_indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The graph patch tokens should be consecutive.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">orig_embeds_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">mask_index_start</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">mask_index_start</span><span class="o">+</span><span class="n">num_patches</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">mask_index_start</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">mask_index_start</span><span class="o">+</span><span class="n">num_patches</span><span class="p">:]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_new_input_embeds</span><span class="p">)</span>
                    <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">assert</span> <span class="n">cur_graph_idx</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">graph_node_features</span><span class="p">)</span>
            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_input_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">HeteroLlamaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span>
        <span class="p">)</span>

<div class="viewcode-block" id="HeteroLlamaForCausalLM"><a class="viewcode-back" href="../../../generated/ggfm.models.HeteroLlamaForCausalLM.html#ggfm.models.HeteroLlamaForCausalLM">[docs]</a><span class="k">class</span> <span class="nc">HeteroLlamaForCausalLM</span><span class="p">(</span><span class="n">LlamaForCausalLM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    HeteroLLaMA model for causal language modeling with heterogeneous graphs.</span>
<span class="sd">    </span>
<span class="sd">    Extends LlamaForCausalLM to support language modeling conditioned on</span>
<span class="sd">    heterogeneous graph structures.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        config (HeteroLlamaConfig): Model configuration</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">config_class</span> <span class="o">=</span> <span class="n">HeteroLlamaConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LlamaForCausalLM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">HeteroLlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

<div class="viewcode-block" id="HeteroLlamaForCausalLM.get_model"><a class="viewcode-back" href="../../../generated/ggfm.models.HeteroLlamaForCausalLM.html#ggfm.models.HeteroLlamaForCausalLM.get_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the underlying HeteroLlamaModel.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>

<div class="viewcode-block" id="HeteroLlamaForCausalLM.get_graph_tower"><a class="viewcode-back" href="../../../generated/ggfm.models.HeteroLlamaForCausalLM.html#ggfm.models.HeteroLlamaForCausalLM.get_graph_tower">[docs]</a>    <span class="k">def</span> <span class="nf">get_graph_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the heterogeneous graph processing component.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span></div>

<div class="viewcode-block" id="HeteroLlamaForCausalLM.forward"><a class="viewcode-back" href="../../../generated/ggfm.models.HeteroLlamaForCausalLM.html#ggfm.models.HeteroLlamaForCausalLM.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">graph_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Data</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hetero_key_order</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">CausalLMOutputWithPast</span><span class="p">]:</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="n">graph_data</span><span class="o">=</span><span class="n">graph_data</span><span class="p">,</span>
            <span class="n">hetero_key_order</span><span class="o">=</span><span class="n">hetero_key_order</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">shift_logits</span><span class="p">,</span> <span class="n">shift_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">CausalLMOutputWithPast</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="HeteroLlamaForCausalLM.prepare_inputs_for_generation"><a class="viewcode-back" href="../../../generated/ggfm.models.HeteroLlamaForCausalLM.html#ggfm.models.HeteroLlamaForCausalLM.prepare_inputs_for_generation">[docs]</a>    <span class="k">def</span> <span class="nf">prepare_inputs_for_generation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">past_key_values</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

        <span class="k">if</span> <span class="n">inputs_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs_embeds&quot;</span><span class="p">:</span> <span class="n">inputs_embeds</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;graph_data&quot;</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
                    <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
                    <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
                    <span class="s2">&quot;graph_data&quot;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="s2">&quot;hetero_key_order&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hetero_key_order&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
                    <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
                    <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
                    <span class="s2">&quot;graph_data&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;graph_data&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                    <span class="s2">&quot;hetero_key_order&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;hetero_key_order&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)]</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">model_inputs</span></div>

<div class="viewcode-block" id="HeteroLlamaForCausalLM.initialize_graph_tokenizer"><a class="viewcode-back" href="../../../generated/ggfm.models.HeteroLlamaForCausalLM.html#ggfm.models.HeteroLlamaForCausalLM.initialize_graph_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_graph_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_graph_start_end</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
                                 <span class="n">tune_graph_mlp_adapter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span><span class="o">.</span><span class="n">config</span>
        <span class="n">vision_config</span><span class="o">.</span><span class="n">use_graph_start_end</span> <span class="o">=</span> <span class="n">use_graph_start_end</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span><span class="p">],</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">use_graph_start_end</span><span class="p">:</span>
            <span class="n">num_new_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="n">DEFAULT_G_START_TOKEN</span><span class="p">,</span> <span class="n">DEFAULT_G_END_TOKEN</span><span class="p">],</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
            <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">,</span> <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_end_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">([</span><span class="n">DEFAULT_G_START_TOKEN</span><span class="p">,</span> <span class="n">DEFAULT_G_END_TOKEN</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">num_new_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">input_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
                <span class="n">output_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>

                <span class="n">input_embeddings_avg</span> <span class="o">=</span> <span class="n">input_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">output_embeddings_avg</span> <span class="o">=</span> <span class="n">output_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">input_embeddings_avg</span>
                <span class="n">output_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">output_embeddings_avg</span>

            <span class="k">if</span> <span class="n">tune_graph_mlp_adapter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">orig_embeds_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)]</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">pretrain_graph_mlp_adapter</span><span class="p">:</span>
                <span class="n">mm_projector_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                <span class="n">embed_tokens_weight</span> <span class="o">=</span> <span class="n">mm_projector_weights</span><span class="p">[</span><span class="s1">&#39;model.embed_tokens.weight&#39;</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">num_new_tokens</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                    <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">embed_tokens_weight</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span>
                <span class="k">elif</span> <span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_new_tokens</span><span class="p">:</span>
                    <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">embed_tokens_weight</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected embed_tokens_weight shape. Pretrained: </span><span class="si">{</span><span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Current: </span><span class="si">{</span><span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Numer of new tokens: </span><span class="si">{</span><span class="n">num_new_tokens</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_patch_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">([</span><span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div></div>


<span class="n">AutoConfig</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">&quot;HeteroLlama&quot;</span><span class="p">,</span> <span class="n">HeteroLlamaConfig</span><span class="p">)</span>
<span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">HeteroLlamaConfig</span><span class="p">,</span> <span class="n">HeteroLlamaForCausalLM</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_tokenize_fn</span><span class="p">(</span><span class="n">strings</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
                 <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">PreTrainedTokenizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize a list of strings.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        strings (Sequence[str]): List of input strings to tokenize</span>
<span class="sd">        tokenizer (PreTrainedTokenizer): Tokenizer to use</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        Dict: Dictionary containing:</span>
<span class="sd">            - input_ids: Token IDs</span>
<span class="sd">            - labels: Labels for language modeling</span>
<span class="sd">            - input_ids_lens: Lengths of input sequences</span>
<span class="sd">            - labels_lens: Lengths of label sequences</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tokenized_list</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">text</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">strings</span>
    <span class="p">]</span>
    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tokenized</span><span class="o">.</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">tokenized</span> <span class="ow">in</span> <span class="n">tokenized_list</span>
    <span class="p">]</span>
    <span class="n">input_ids_lens</span> <span class="o">=</span> <span class="n">labels_lens</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">tokenized</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">tokenized</span> <span class="ow">in</span> <span class="n">tokenized_list</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">input_ids_lens</span><span class="o">=</span><span class="n">input_ids_lens</span><span class="p">,</span>
        <span class="n">labels_lens</span><span class="o">=</span><span class="n">labels_lens</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">def</span> <span class="nf">_mask_targets</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">tokenized_lens</span><span class="p">,</span> <span class="n">speakers</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Mask target tokens for dialogue modeling.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        target: Target token IDs to mask</span>
<span class="sd">        tokenized_lens: List of token sequence lengths</span>
<span class="sd">        speakers: List of speaker identifiers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cur_idx</span> <span class="o">=</span> <span class="n">tokenized_lens</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">tokenized_lens</span> <span class="o">=</span> <span class="n">tokenized_lens</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="n">target</span><span class="p">[:</span><span class="n">cur_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">IGNORE_INDEX</span>
    <span class="k">for</span> <span class="n">tokenized_len</span><span class="p">,</span> <span class="n">speaker</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tokenized_lens</span><span class="p">,</span> <span class="n">speakers</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">speaker</span> <span class="o">==</span> <span class="s2">&quot;human&quot;</span><span class="p">:</span>
            <span class="n">target</span><span class="p">[</span><span class="n">cur_idx</span><span class="o">+</span><span class="mi">2</span><span class="p">:</span><span class="n">cur_idx</span> <span class="o">+</span> <span class="n">tokenized_len</span><span class="p">]</span> <span class="o">=</span> <span class="n">IGNORE_INDEX</span>
        <span class="n">cur_idx</span> <span class="o">+=</span> <span class="n">tokenized_len</span>

<span class="k">def</span> <span class="nf">smart_tokenizer_and_embedding_resize</span><span class="p">(</span>
    <span class="n">special_tokens_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">PreTrainedTokenizer</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">PreTrainedModel</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize tokenizer and embedding layers to accommodate new special tokens.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        special_tokens_dict (Dict): Dictionary of special tokens to add</span>
<span class="sd">        tokenizer (PreTrainedTokenizer): Tokenizer to modify</span>
<span class="sd">        model (PreTrainedModel): Model whose embeddings need resizing</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_new_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">(</span><span class="n">special_tokens_dict</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">num_new_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">input_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
        <span class="n">output_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>

        <span class="n">input_embeddings_avg</span> <span class="o">=</span> <span class="n">input_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">output_embeddings_avg</span> <span class="o">=</span> <span class="n">output_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">input_embeddings_avg</span>
        <span class="n">output_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">output_embeddings_avg</span>

<span class="k">def</span> <span class="nf">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Recursively unwrap a model from potential containers.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model (nn.Module): Model to unwrap</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        nn.Module: Unwrapped model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;module&quot;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">find_all_linear_names</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find all linear layer names in the model.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        model: Model to analyze</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        list: List of linear layer names, excluding lm_head</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">cls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
    <span class="n">lora_module_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">cls</span><span class="p">):</span>
            <span class="n">names</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
            <span class="n">lora_module_names</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">names</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="s1">&#39;lm_head&#39;</span> <span class="ow">in</span> <span class="n">lora_module_names</span><span class="p">:</span>
        <span class="n">lora_module_names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;lm_head&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">lora_module_names</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">safe_save_model_for_hf_trainer</span><span class="p">(</span><span class="n">trainer</span><span class="p">:</span> <span class="n">transformers</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Collects the state dict and saves model to disk safely.</span>
<span class="sd">    </span>
<span class="sd">    Handles DeepSpeed and regular model saving with proper synchronization.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        trainer (transformers.Trainer): HuggingFace trainer instance</span>
<span class="sd">        output_dir (str): Directory to save model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">deepspeed</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">output_dir</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">should_save</span><span class="p">:</span>
        <span class="n">cpu_state_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">key</span><span class="p">:</span> <span class="n">value</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="k">del</span> <span class="n">state_dict</span>
        <span class="n">trainer</span><span class="o">.</span><span class="n">_save</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="n">cpu_state_dict</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_peft_state_maybe_zero_3</span><span class="p">(</span><span class="n">named_params</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get PEFT state dict handling DeepSpeed ZeRO-3.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        named_params: Named parameters from model</span>
<span class="sd">        bias (str): Bias handling mode (&#39;none&#39;, &#39;all&#39;, or &#39;lora_only&#39;)</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        dict: State dict with gathered parameters</span>
<span class="sd">        </span>
<span class="sd">    Raises:</span>
<span class="sd">        NotImplementedError: If bias mode is not recognized</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="o">==</span> <span class="s2">&quot;none&quot;</span><span class="p">:</span>
        <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">t</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">named_params</span> <span class="k">if</span> <span class="s2">&quot;lora_&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">}</span>
    <span class="k">elif</span> <span class="n">bias</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
        <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">t</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">named_params</span> <span class="k">if</span> <span class="s2">&quot;lora_&quot;</span> <span class="ow">in</span> <span class="n">k</span> <span class="ow">or</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">}</span>
    <span class="k">elif</span> <span class="n">bias</span> <span class="o">==</span> <span class="s2">&quot;lora_only&quot;</span><span class="p">:</span>
        <span class="n">to_return</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">maybe_lora_bias</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">lora_bias_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">named_params</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;lora_&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">:</span>
                <span class="n">to_return</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span>
                <span class="n">bias_name</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;lora_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;bias&quot;</span>
                <span class="n">lora_bias_names</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">bias_name</span><span class="p">)</span>
            <span class="k">elif</span> <span class="s2">&quot;bias&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">:</span>
                <span class="n">maybe_lora_bias</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">maybe_lora_bias</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">bias_name</span> <span class="ow">in</span> <span class="n">lora_bias_names</span><span class="p">:</span>
                <span class="n">to_return</span><span class="p">[</span><span class="n">bias_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
    <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">maybe_zero_3</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">to_return</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">return</span> <span class="n">to_return</span>

<span class="k">def</span> <span class="nf">get_peft_state_non_lora_maybe_zero_3</span><span class="p">(</span><span class="n">named_params</span><span class="p">,</span> <span class="n">require_grad_only</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get non-LoRA PEFT state dict handling DeepSpeed ZeRO-3.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        named_params: Named parameters from model</span>
<span class="sd">        require_grad_only (bool, optional): Whether to only include parameters requiring gradients. Defaults to True</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        dict: State dict with gathered parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">t</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">named_params</span> <span class="k">if</span> <span class="s2">&quot;lora_&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">require_grad_only</span><span class="p">:</span>
        <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">t</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">to_return</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">}</span>
    <span class="n">to_return</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">maybe_zero_3</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ignore_status</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">to_return</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="k">return</span> <span class="n">to_return</span>

<span class="k">def</span> <span class="nf">maybe_zero_3</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">ignore_status</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Handle DeepSpeed ZeRO-3 parameters.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        param: Model parameter</span>
<span class="sd">        ignore_status (bool, optional): Whether to ignore parameter status. Defaults to False</span>
<span class="sd">        name (str, optional): Parameter name for logging. Defaults to None</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: Gathered parameter data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># from deepspeed import zero</span>
    <span class="c1"># from deepspeed.runtime.zero.partition_parameters import ZeroParamStatus</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="s2">&quot;ds_id&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">ds_status</span> <span class="o">==</span> <span class="n">ZeroParamStatus</span><span class="o">.</span><span class="n">NOT_AVAILABLE</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">ignore_status</span><span class="p">:</span>
                <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: param.ds_status != ZeroParamStatus.NOT_AVAILABLE: </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">ds_status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">zero</span><span class="o">.</span><span class="n">GatheredParameters</span><span class="p">([</span><span class="n">param</span><span class="p">]):</span>
            <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">param</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">param</span>

<span class="k">def</span> <span class="nf">download_cached_file</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">check_hash</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Download a file from URL and cache it locally.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        url (str): URL to download from</span>
<span class="sd">        check_hash (bool, optional): Whether to verify file hash. Defaults to True</span>
<span class="sd">        progress (bool, optional): Whether to show progress bar. Defaults to True</span>
<span class="sd">        </span>
<span class="sd">    Returns:</span>
<span class="sd">        str: Path to cached file</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">torch.hub</span> <span class="kn">import</span> <span class="n">download_url_to_file</span><span class="p">,</span> <span class="n">get_dir</span>
    <span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlparse</span>
    <span class="kn">import</span> <span class="nn">os</span>

    <span class="n">parts</span> <span class="o">=</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">parts</span><span class="o">.</span><span class="n">path</span><span class="p">)</span>
    <span class="n">cached_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">get_dir</span><span class="p">(),</span> <span class="n">filename</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">cached_file</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Downloading: &quot;</span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="s1">&quot; to </span><span class="si">{</span><span class="n">cached_file</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="n">download_url_to_file</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">cached_file</span><span class="p">,</span> <span class="n">hash_prefix</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="n">progress</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cached_file</span>


<span class="k">class</span> <span class="nc">MetaHeteroLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Meta-learning based linear layer for heterogeneous inputs.</span>
<span class="sd">    </span>
<span class="sd">    Implements a dynamic or static linear transformation that can handle</span>
<span class="sd">    different types of inputs through meta-learning.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        text_width (int): Width of text embeddings for generating weights</span>
<span class="sd">        in_features (int): Input feature dimension</span>
<span class="sd">        out_features (int): Output feature dimension</span>
<span class="sd">        dynamic (bool, optional): Whether to use dynamic weight generation. Defaults to True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_width</span> <span class="o">=</span> <span class="n">text_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span> <span class="o">=</span> <span class="n">dynamic</span>

        <span class="k">if</span> <span class="n">dynamic</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_width</span><span class="p">,</span> <span class="n">in_features</span> <span class="o">*</span> <span class="n">out_features</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_width</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">/</span> <span class="n">in_features</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_features</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">type_id</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">type_embed_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass with type-specific transformations.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x (Tensor): Input features</span>
<span class="sd">            type_id (Tensor): Type IDs for each input</span>
<span class="sd">            type_embed_dict (Dict[int, Tensor]): Type embeddings dictionary</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Transformed features</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">type_embed_dict</span><span class="p">)):</span>
                <span class="n">type_embed</span> <span class="o">=</span> <span class="n">type_embed_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">cur_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_proj</span><span class="p">(</span><span class="n">type_embed</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">)</span>
                <span class="n">cur_bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_proj</span><span class="p">(</span><span class="n">type_embed</span><span class="p">)</span>
                <span class="n">weight</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_weight</span><span class="p">)</span>
                <span class="n">bias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_bias</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">bias</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[</span><span class="n">type_id</span><span class="p">]</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="p">[</span><span class="n">type_id</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
            <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MetaHeteroDictLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Meta-learning based linear layer for dictionary of heterogeneous inputs.</span>
<span class="sd">    </span>
<span class="sd">    Similar to MetaHeteroLinear but handles dictionary inputs where each key</span>
<span class="sd">    represents a different node/edge type.</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        text_width (int): Width of text embeddings for generating weights</span>
<span class="sd">        in_features (int): Input feature dimension</span>
<span class="sd">        out_features (int): Output feature dimension</span>
<span class="sd">        dynamic (bool, optional): Whether to use dynamic weight generation. Defaults to True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">in_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_features</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">text_width</span> <span class="o">=</span> <span class="n">text_width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">in_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span> <span class="o">=</span> <span class="n">out_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span> <span class="o">=</span> <span class="n">dynamic</span>

        <span class="k">if</span> <span class="n">dynamic</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_width</span><span class="p">,</span> <span class="n">in_features</span> <span class="o">*</span> <span class="n">out_features</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">text_width</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span> <span class="o">/</span> <span class="n">in_features</span> <span class="o">**</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_features</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span> <span class="n">type_embed_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass with type-specific transformations on dictionary inputs.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            x_dict (Dict[str, Tensor]): Dictionary of input features by type</span>
<span class="sd">            type_embed_dict (Dict[str, Tensor]): Dictionary of type embeddings</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, Tensor]: Dictionary of transformed features by type</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">out_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">node_type</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dynamic</span><span class="p">:</span>
                <span class="n">type_embed</span> <span class="o">=</span> <span class="n">type_embed_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_proj</span><span class="p">(</span><span class="n">type_embed</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_features</span><span class="p">)</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_proj</span><span class="p">(</span><span class="n">type_embed</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
            <span class="n">out_dict</span><span class="p">[</span><span class="n">node_type</span><span class="p">]</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out_dict</span>


<span class="k">class</span> <span class="nc">HeteClipLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Contrastive loss for heterogeneous CLIP model.</span>
<span class="sd">    </span>
<span class="sd">    Implements InfoNCE-style contrastive loss between graph and text embeddings</span>
<span class="sd">    with temperature scaling.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_local_batch_size</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_features</span><span class="p">,</span> <span class="n">text_features</span><span class="p">,</span> <span class="n">logit_scale</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute contrastive loss between graph and text features.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            graph_features (Tensor): Graph embeddings</span>
<span class="sd">            text_features (Tensor): Text embeddings</span>
<span class="sd">            logit_scale (Tensor): Temperature scaling factor</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Contrastive loss value</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">graph_features</span><span class="o">.</span><span class="n">device</span>
        <span class="n">local_batch_size</span> <span class="o">=</span> <span class="n">graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">local_batch_size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_local_batch_size</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">local_batch_size</span> <span class="o">*</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">last_local_batch_size</span> <span class="o">=</span> <span class="n">local_batch_size</span>


        <span class="n">graph_features</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">graph_features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">text_features</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">text_features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits_per_graph</span> <span class="o">=</span> <span class="n">logit_scale</span> <span class="o">*</span> <span class="n">graph_features</span> <span class="o">@</span> <span class="n">text_features</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="n">logits_per_text</span> <span class="o">=</span> <span class="n">logits_per_graph</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits_per_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">+</span>
            <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits_per_text</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>

        <span class="k">return</span> <span class="n">loss</span>

<span class="n">openai_imagenet_template</span> <span class="o">=</span> <span class="p">[</span>
    <span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;a photo of a </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
    <span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;a photograph of a </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
    <span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;an image of a </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
    <span class="k">lambda</span> <span class="n">c</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;a picture of a </span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, BUPT-GAMMA LAB.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>