

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ggfm.models.graphgpt &mdash; GGFM 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />

  
      <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=e031e9a9"></script>
      <script src="../../../_static/doctools.js?v=888ff710"></script>
      <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            GGFM
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">NOTES</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/install.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/developer_guide.html">Developer Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.data.html">ggfm.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.conv.html">ggfm.conv</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.models.html">ggfm.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/ggfm.evaluate.html">ggfm.evaluation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">GGFM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">ggfm.models.graphgpt</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for ggfm.models.graphgpt</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">html</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span>

<span class="kn">import</span> <span class="nn">ftfy</span>
<span class="kn">import</span> <span class="nn">regex</span> <span class="k">as</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">lightning.pytorch</span> <span class="kn">import</span> <span class="n">LightningModule</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">get_cosine_schedule_with_warmup</span><span class="p">,</span>
                          <span class="n">AutoConfig</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span>
                         <span class="n">LlamaConfig</span><span class="p">,</span> <span class="n">LlamaModel</span><span class="p">,</span> <span class="n">LlamaForCausalLM</span><span class="p">)</span>
                        <span class="c1">#  BaseModelOutputWithPast, CausalLMOutputWithPast)</span>
<span class="kn">from</span> <span class="nn">transformers.configuration_utils</span> <span class="kn">import</span> <span class="n">PretrainedConfig</span>

<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">torch_geometric.data</span> <span class="kn">import</span> <span class="n">Data</span>
<span class="c1"># from torch_geometric.data import Data, remove_self_loops, add_self_loops, degree</span>
<span class="kn">from</span> <span class="nn">torch_geometric.utils</span> <span class="kn">import</span> <span class="n">add_remaining_self_loops</span>
<span class="c1"># from torch_scatter import scatter_add</span>
<span class="kn">from</span> <span class="nn">torch_geometric.nn.conv</span> <span class="kn">import</span> <span class="n">MessagePassing</span>

<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os.path</span> <span class="k">as</span> <span class="nn">osp</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>


<span class="n">DEFAULT_GRAPH_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;graph&gt;&quot;</span>
<span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;g_patch&gt;&quot;</span>
<span class="n">DEFAULT_G_START_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;g_start&gt;&quot;</span>
<span class="n">DEFAULT_G_END_TOKEN</span> <span class="o">=</span> <span class="s2">&quot;&lt;g_end&gt;&quot;</span>


<span class="c1">############# basic conv layers #############</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span>
<span class="n">uniformInit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform</span>

<span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">t</span>
<span class="kn">import</span> <span class="nn">math</span>


<span class="k">def</span> <span class="nf">gcn_conv</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Convolutional Network layer</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    h</span>
<span class="sd">    edge_index</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># print(edge_index)</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">node_feas</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">remove_self_loops</span><span class="p">(</span><span class="n">edge_index</span><span class="p">)</span>
    <span class="n">edge_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">add_self_loops</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>

    <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="o">=</span> <span class="n">edge_index</span>
    <span class="n">deg</span> <span class="o">=</span> <span class="n">degree</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>

    <span class="n">deg_src</span> <span class="o">=</span> <span class="n">deg</span><span class="p">[</span><span class="n">src</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">deg_src</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">deg_src</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">deg_dst</span> <span class="o">=</span> <span class="n">deg</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">deg_dst</span><span class="o">.</span><span class="n">masked_fill_</span><span class="p">(</span><span class="n">deg_dst</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">edge_weight</span> <span class="o">=</span> <span class="n">deg_src</span> <span class="o">*</span> <span class="n">deg_dst</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">N</span><span class="p">]))</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
    <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">edge_index</span>
    <span class="n">edge_msg</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">edge_weight</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">col_embeds</span> <span class="o">=</span> <span class="n">h</span><span class="p">[</span><span class="n">cols</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">tem</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">N</span><span class="p">,</span> <span class="n">node_feas</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">edge_msg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="n">rows</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">edge_msg</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">h_prime</span> <span class="o">=</span> <span class="n">tem</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">edge_msg</span><span class="p">)</span>  <span class="c1"># nd</span>
    <span class="c1"># h = h.float()</span>
    <span class="c1"># h_prime = a @ h</span>
    <span class="c1"># h_prime = h_prime.bfloat16()</span>
    <span class="k">return</span> <span class="n">h_prime</span>


<span class="c1"># Implementation of MPNN, which can become MLP or GCN depending on whether using message passing</span>
<div class="viewcode-block" id="MPNN"><a class="viewcode-back" href="../../../generated/ggfm.models.MPNN.html#ggfm.models.MPNN">[docs]</a><span class="k">class</span> <span class="nc">MPNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Message Passing Neural Network (MPNN) layer</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    in_channels : int</span>
<span class="sd">        Number of input features</span>
<span class="sd">    hidden_channels : int</span>
<span class="sd">        Number of hidden features</span>
<span class="sd">    out_channels : int</span>
<span class="sd">        Number of output features</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MPNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dropout&#39;</span><span class="p">)</span>  <span class="c1"># args.dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_layers&#39;</span><span class="p">)</span>  <span class="c1"># args.num_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># Use bias for FF layers in default</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bns</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;if_param&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span><span class="p">))</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span><span class="p">))</span>  <span class="c1"># 1s</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span><span class="p">))</span>  <span class="c1"># 1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>

<div class="viewcode-block" id="MPNN.reset_parameters"><a class="viewcode-back" href="../../../generated/ggfm.models.MPNN.html#ggfm.models.MPNN.reset_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">mlp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.414</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">mlp</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span></div>

<div class="viewcode-block" id="MPNN.forward"><a class="viewcode-back" href="../../../generated/ggfm.models.MPNN.html#ggfm.models.MPNN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">use_conv</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of MPNN layer</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        g</span>
<span class="sd">        use_conv</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_node</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span><span class="o">.</span><span class="fm">__next__</span><span class="p">()</span><span class="o">.</span><span class="n">device</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">edge_index</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">use_conv</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">gcn_conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                                      <span class="n">edge_index</span><span class="p">)</span>  <span class="c1"># Optionally replace &#39;gcn_conv&#39; with other conv functions in conv.py</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bns</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">((</span><span class="n">x</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_conv</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">gcn_conv</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ff_bias</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">if_param</span><span class="p">:</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">fcs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>
        <span class="k">return</span> <span class="n">x</span></div></div>


<span class="k">def</span> <span class="nf">PositionalEncoding</span><span class="p">(</span><span class="n">q_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Positional encoding for the transformer</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    q_len</span>
<span class="sd">    d_model</span>
<span class="sd">    normalize</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pe</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">q_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
    <span class="n">position</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">q_len</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">div_term</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
    <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
    <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span> <span class="o">-</span> <span class="n">pe</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span> <span class="o">/</span> <span class="p">(</span><span class="n">pe</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pe</span>


<span class="k">def</span> <span class="nf">pos_encoding</span><span class="p">(</span><span class="n">pe</span><span class="p">,</span> <span class="n">learn_pe</span><span class="p">,</span> <span class="n">nvar</span><span class="p">,</span> <span class="n">d_model</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Positional encoding</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pe</span>
<span class="sd">    learn_pe</span>
<span class="sd">    nvar</span>
<span class="sd">    d_model</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">pe</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">W_pos</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nvar</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W_pos</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
        <span class="n">learn_pe</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">pe</span> <span class="o">==</span> <span class="s1">&#39;zero&#39;</span><span class="p">:</span>
        <span class="n">W_pos</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nvar</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W_pos</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">pe</span> <span class="o">==</span> <span class="s1">&#39;zeros&#39;</span><span class="p">:</span>
        <span class="n">W_pos</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nvar</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W_pos</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">pe</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span> <span class="ow">or</span> <span class="n">pe</span> <span class="o">==</span> <span class="s1">&#39;gauss&#39;</span><span class="p">:</span>
        <span class="n">W_pos</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nvar</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">t</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">W_pos</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">pe</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
        <span class="n">W_pos</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">nvar</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">W_pos</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">pe</span> <span class="o">==</span> <span class="s1">&#39;sincos&#39;</span><span class="p">:</span>
        <span class="n">W_pos</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">nvar</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pe</span><span class="si">}</span><span class="s2"> is not a valid pe (positional encoder. Available types: &#39;gauss&#39;==&#39;normal&#39;, </span><span class="se">\</span>
<span class="s2">        &#39;zeros&#39;, &#39;zero&#39;, uniform&#39;, &#39;sincos&#39;, None.)&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">W_pos</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">learn_pe</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">graph_transformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Transformer layer</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">graph_transformer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gtLayers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">GTLayer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gt_layers</span><span class="p">)])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W_pos</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W_P</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_input</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inverW_P</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass of the graph transformer layer</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        g</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Adj: sp adj</span>
        <span class="c1"># x: bs * n * d_model * num_patch</span>

        <span class="c1"># print(edge_index)</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span><span class="o">.</span><span class="fm">__next__</span><span class="p">()</span><span class="o">.</span><span class="n">device</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_node</span>

        <span class="c1"># x, W_P_weight, W_P_bias= Mv2Samedevice([x, self.W_P.weight, self.W_P.bias])</span>
        <span class="c1"># self.W_P.weight = nn.Parameter(W_P_weight.to(x.dtype))</span>
        <span class="c1"># self.W_P.bias = nn.Parameter(W_P_bias.to(x.dtype))</span>
        <span class="c1"># print(self.W_P.dtype, x.dtype)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_P</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">if_pos</span><span class="p">:</span>
            <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">z</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_pos</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">gt</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">gtLayers</span><span class="p">:</span>
            <span class="n">embeds</span> <span class="o">=</span> <span class="n">gt</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">embeds</span><span class="p">)</span>  <span class="c1"># bs * num_patch * n * d_model</span>
        <span class="c1"># embeds, inverW_P_weight, inverW_P_bias = Mv2Samedevice([embeds, self.inverW_P.weight, self.inverW_P.bias])</span>
        <span class="c1"># self.inverW_P.weight = nn.Parameter(inverW_P_weight.to(embeds.dtype))</span>
        <span class="c1"># self.inverW_P.bias = nn.Parameter(inverW_P_bias.to(embeds.dtype))</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inverW_P</span><span class="p">(</span><span class="n">embeds</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ret</span>


<span class="k">def</span> <span class="nf">Mv2Samedevice</span><span class="p">(</span><span class="nb">vars</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">var</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="nb">vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="nb">vars</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">GTLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Transformer layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GTLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qTrans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kTrans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vTrans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">att_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">embeds</span><span class="p">):</span>
        <span class="c1"># Adj: adj</span>
        <span class="c1"># x: n * d_model</span>
        <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">nvar</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">embeds</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># print(rows)</span>
        <span class="c1"># print(cols)</span>

        <span class="n">rowEmbeds</span> <span class="o">=</span> <span class="n">embeds</span><span class="p">[</span><span class="n">rows</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">colEmbeds</span> <span class="o">=</span> <span class="n">embeds</span><span class="p">[</span><span class="n">cols</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">evar</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">rowEmbeds</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># rowEmbeds, qTrans, kTrans, vTrans = Mv2Samedevice([rowEmbeds, self.qTrans, self.kTrans, self.vTrans])</span>
        <span class="c1"># self.qTrans = nn.Parameter(qTrans.to(rowEmbeds.dtype))</span>
        <span class="c1"># self.kTrans = nn.Parameter(kTrans.to(rowEmbeds.dtype))</span>
        <span class="c1"># self.vTrans = nn.Parameter(vTrans.to(rowEmbeds.dtype))</span>
        <span class="n">qEmbeds</span> <span class="o">=</span> <span class="p">(</span><span class="n">rowEmbeds</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">qTrans</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">evar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">])</span>
        <span class="n">kEmbeds</span> <span class="o">=</span> <span class="p">(</span><span class="n">colEmbeds</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">kTrans</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">evar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">])</span>
        <span class="n">vEmbeds</span> <span class="o">=</span> <span class="p">(</span><span class="n">colEmbeds</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">vTrans</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">evar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">])</span>

        <span class="n">att</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ehd, ehd -&gt; eh&#39;</span><span class="p">,</span> <span class="n">qEmbeds</span><span class="p">,</span> <span class="n">kEmbeds</span><span class="p">)</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">att</span><span class="p">,</span> <span class="o">-</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
        <span class="n">expAtt</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">att</span><span class="p">)</span>

        <span class="n">tem</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nvar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">head</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">expAtt</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">expAtt</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># print(tem.device, expAtt.device, rows.device)</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="n">rows</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">expAtt</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">attNorm</span> <span class="o">=</span> <span class="p">(</span><span class="n">tem</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">expAtt</span><span class="p">))[</span><span class="n">rows</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">att</span> <span class="o">=</span> <span class="n">expAtt</span> <span class="o">/</span> <span class="p">(</span><span class="n">attNorm</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>  <span class="c1"># bleh</span>

        <span class="n">resEmbeds</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;eh, ehd -&gt; ehd&#39;</span><span class="p">,</span> <span class="n">att</span><span class="p">,</span> <span class="n">vEmbeds</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">evar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">])</span>
        <span class="n">tem</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">nvar</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">att_d_model</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">resEmbeds</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">resEmbeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">rows</span> <span class="o">=</span> <span class="n">rows</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">resEmbeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">tem</span> <span class="o">=</span> <span class="n">tem</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">resEmbeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">resEmbeds</span> <span class="o">=</span> <span class="n">tem</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">rows</span><span class="p">,</span> <span class="n">resEmbeds</span><span class="p">)</span>  <span class="c1"># nd</span>
        <span class="n">resEmbeds</span> <span class="o">=</span> <span class="n">resEmbeds</span> <span class="o">+</span> <span class="n">embeds</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">att_norm</span><span class="p">:</span>
            <span class="c1"># resEmbeds, norm_weight, norm_bias = Mv2Samedevice([resEmbeds, self.norm.weight, self.norm.bias])</span>
            <span class="c1"># self.norm.weight = nn.Parameter(norm_weight.to(resEmbeds.dtype))</span>
            <span class="c1"># self.norm.bias = nn.Parameter(norm_bias.to(resEmbeds.dtype))</span>
            <span class="n">resEmbeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">resEmbeds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">resEmbeds</span>
<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">default_bpe</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="vm">__file__</span><span class="p">)),</span> <span class="s2">&quot;bpe_simple_vocab_16e6.txt.gz&quot;</span><span class="p">)</span>


<span class="nd">@lru_cache</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">bytes_to_unicode</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns list of utf-8 byte and a corresponding list of unicode strings.</span>
<span class="sd">    The reversible bpe codes work on unicode strings.</span>
<span class="sd">    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.</span>
<span class="sd">    When you&#39;re at something like a 10B token dataset you end up needing around 5K for decent coverage.</span>
<span class="sd">    This is a signficant percentage of your normal, say, 32K bpe vocab.</span>
<span class="sd">    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.</span>
<span class="sd">    And avoids mapping to whitespace/control characters the bpe code barfs on.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;!&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;~&quot;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;¡&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;¬&quot;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;®&quot;</span><span class="p">),</span> <span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;ÿ&quot;</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="n">bs</span><span class="p">[:]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">b</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bs</span><span class="p">:</span>
            <span class="n">bs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="n">cs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">2</span><span class="o">**</span><span class="mi">8</span><span class="o">+</span><span class="n">n</span><span class="p">)</span>
            <span class="n">n</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">cs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">chr</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">cs</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">cs</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return set of symbol pairs in a word.</span>
<span class="sd">    Word is represented as tuple of symbols (symbols being variable-length strings).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pairs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">prev_char</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
        <span class="n">pairs</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">prev_char</span><span class="p">,</span> <span class="n">char</span><span class="p">))</span>
        <span class="n">prev_char</span> <span class="o">=</span> <span class="n">char</span>
    <span class="k">return</span> <span class="n">pairs</span>


<span class="k">def</span> <span class="nf">basic_clean</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Basic cleaning of text</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    text</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">ftfy</span><span class="o">.</span><span class="n">fix_text</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">html</span><span class="o">.</span><span class="n">unescape</span><span class="p">(</span><span class="n">html</span><span class="o">.</span><span class="n">unescape</span><span class="p">(</span><span class="n">text</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">whitespace_clean</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">text</span>


<span class="k">class</span> <span class="nc">SimpleTokenizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple tokenizer</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bpe_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">default_bpe</span><span class="p">()):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span> <span class="o">=</span> <span class="n">bytes_to_unicode</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="c1"># merges = gzip.open(bpe_path).read().decode(&quot;utf-8&quot;).split(&#39;\n&#39;)</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="n">merges</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">49152</span><span class="o">-</span><span class="mi">256</span><span class="o">-</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">merges</span> <span class="o">=</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">(</span><span class="n">merge</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">merge</span> <span class="ow">in</span> <span class="n">merges</span><span class="p">]</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">bytes_to_unicode</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span> <span class="o">+</span> <span class="p">[</span><span class="n">v</span><span class="o">+</span><span class="s1">&#39;&lt;/w&gt;&#39;</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vocab</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">merge</span> <span class="ow">in</span> <span class="n">merges</span><span class="p">:</span>
            <span class="n">vocab</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">merge</span><span class="p">))</span>
        <span class="n">vocab</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;&lt;|startoftext|&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">vocab</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">merges</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">merges</span><span class="p">))))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;&lt;|startoftext|&gt;&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;|startoftext|&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">:</span> <span class="s1">&#39;&lt;|endoftext|&gt;&#39;</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;&quot;&quot;&lt;\|startoftext\|&gt;|&lt;\|endoftext\|&gt;|&#39;s|&#39;t|&#39;re|&#39;ve|&#39;m|&#39;ll|&#39;d|[\p</span><span class="si">{L}</span><span class="s2">]+|[\p</span><span class="si">{N}</span><span class="s2">]|[^\s\p</span><span class="si">{L}</span><span class="s2">\p</span><span class="si">{N}</span><span class="s2">]+&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">bpe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span>
        <span class="n">word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">token</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span> <span class="n">token</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;&lt;/w&gt;&#39;</span><span class="p">,)</span>
        <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">pairs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">token</span><span class="o">+</span><span class="s1">&#39;&lt;/w&gt;&#39;</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">bigram</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">pairs</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">pair</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)))</span>
            <span class="k">if</span> <span class="n">bigram</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe_ranks</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">first</span><span class="p">,</span> <span class="n">second</span> <span class="o">=</span> <span class="n">bigram</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">j</span> <span class="o">=</span> <span class="n">word</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">first</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">j</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">=</span> <span class="n">j</span>
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
                    <span class="k">break</span>

                <span class="k">if</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">first</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">second</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">first</span><span class="o">+</span><span class="n">second</span><span class="p">)</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">2</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_word</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">new_word</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_word</span><span class="p">)</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">new_word</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">pairs</span> <span class="o">=</span> <span class="n">get_pairs</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
        <span class="k">return</span> <span class="n">word</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">bpe_tokens</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">whitespace_clean</span><span class="p">(</span><span class="n">basic_clean</span><span class="p">(</span><span class="n">text</span><span class="p">))</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pat</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
            <span class="n">token</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_encoder</span><span class="p">[</span><span class="n">b</span><span class="p">]</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">token</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
            <span class="n">bpe_tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="n">bpe_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">bpe_token</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">bpe</span><span class="p">(</span><span class="n">token</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">bpe_tokens</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
        <span class="n">text</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">])</span>
        <span class="n">text</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">byte_decoder</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;replace&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;&lt;/w&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">text</span>

<span class="c1"># _tokenizer = SimpleTokenizer()</span>


<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Subclass torch&#39;s LayerNorm to handle fp16.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">orig_type</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">ret</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">orig_type</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">QuickGELU</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Quick GELU activation function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">1.702</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ResidualAttentionBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Residual Attention Block</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    d_model : int</span>
<span class="sd">        Dimension of the model</span>
<span class="sd">    n_head : int</span>
<span class="sd">        Number of heads</span>
<span class="sd">    attn_mask : torch.Tensor</span>
<span class="sd">        Attention mask</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_head</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_head</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_1</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">([</span>
            <span class="p">(</span><span class="s2">&quot;c_fc&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)),</span>
            <span class="p">(</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span> <span class="n">QuickGELU</span><span class="p">()),</span>
            <span class="p">(</span><span class="s2">&quot;c_proj&quot;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_2</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span> <span class="o">=</span> <span class="n">attn_mask</span>

    <span class="k">def</span> <span class="nf">attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">need_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_mask</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ln_2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="k">class</span> <span class="nc">Transformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transformer layer</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    width : int</span>
<span class="sd">        Width of the model</span>
<span class="sd">    layers : int</span>
<span class="sd">        Number of layers</span>
<span class="sd">    heads : int</span>
<span class="sd">        Number of heads</span>
<span class="sd">    attn_mask : torch.Tensor</span>
<span class="sd">        Attention mask</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">heads</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resblocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">ResidualAttentionBlock</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">heads</span><span class="p">,</span> <span class="n">attn_mask</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layers</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">resblocks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">MessagePassing</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Neural Network layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">aggr</span><span class="o">=</span><span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">PretrainedConfig</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>

        <span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_hid</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_input</span><span class="p">]))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_hid</span><span class="p">)))</span>

        <span class="n">w</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_hid</span><span class="p">]))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">)))</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">,</span> <span class="n">improved</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">edge_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">edge_index</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                                 <span class="n">device</span><span class="o">=</span><span class="n">edge_index</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">fill_value</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">improved</span> <span class="k">else</span> <span class="mf">2.0</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_weight</span> <span class="o">=</span> <span class="n">add_remaining_self_loops</span><span class="p">(</span>
            <span class="n">edge_index</span><span class="p">,</span> <span class="n">edge_weight</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>

        <span class="n">row</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="n">edge_index</span>
        <span class="n">deg</span> <span class="o">=</span> <span class="n">scatter_add</span><span class="p">(</span><span class="n">edge_weight</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim_size</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">)</span>
        <span class="n">deg_inv_sqrt</span> <span class="o">=</span> <span class="n">deg</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">deg_inv_sqrt</span> <span class="o">==</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="n">edge_index</span><span class="p">,</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">row</span><span class="p">]</span> <span class="o">*</span> <span class="n">edge_weight</span> <span class="o">*</span> <span class="n">deg_inv_sqrt</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">edge_index</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">edge_index</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">graph_node</span>
        <span class="k">if</span> <span class="nb">vars</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">vars</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span>
        <span class="n">improved</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">),</span> <span class="n">improved</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">w</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="nb">vars</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">edge_index</span><span class="p">,</span> <span class="n">norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_dim</span><span class="p">),</span> <span class="n">improved</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="n">edge_index</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">vars</span>


<span class="k">def</span> <span class="nf">Mv2SameDevice</span><span class="p">(</span><span class="n">var_list</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Move all variables in the list to the same device</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    var_list</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">vid</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">var_list</span><span class="p">)):</span>
        <span class="n">var_list</span><span class="p">[</span><span class="n">vid</span><span class="p">]</span> <span class="o">=</span> <span class="n">var_list</span><span class="p">[</span><span class="n">vid</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">var_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">var_list</span>


<div class="viewcode-block" id="CLIP"><a class="viewcode-back" href="../../../generated/ggfm.models.CLIP.html#ggfm.models.CLIP">[docs]</a><span class="k">class</span> <span class="nc">CLIP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CLIP model class</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">args</span>
                 <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">context_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="n">args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_coef</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">edge_coef</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_type</span> <span class="o">==</span> <span class="s1">&#39;gcn&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_type</span> <span class="o">==</span> <span class="s1">&#39;gt&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span>
            <span class="n">width</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_width</span><span class="p">,</span>
            <span class="n">layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_layers</span><span class="p">,</span>
            <span class="n">heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_heads</span><span class="p">,</span>
            <span class="n">attn_mask</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">build_attention_mask</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span>
                                            <span class="n">args</span><span class="o">.</span><span class="n">transformer_width</span><span class="p">)</span>  <span class="c1"># the embedding for all possible tokens</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">transformer_width</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln_final</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_width</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">transformer_width</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">embed_dim</span><span class="p">))</span>
        <span class="c1"># self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))</span>

        <span class="k">if</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_type</span> <span class="o">==</span> <span class="s1">&#39;gcn&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span><span class="o">.</span><span class="n">vars</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">elif</span> <span class="n">args</span><span class="o">.</span><span class="n">gnn_type</span> <span class="o">==</span> <span class="s1">&#39;gt&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span><span class="o">.</span><span class="n">W_pos</span><span class="o">.</span><span class="n">dtype</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">},</span>
                                 <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="p">},</span>
                                 <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">parameters</span><span class="p">()},</span>
                                 <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">},</span>
                                 <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span><span class="o">.</span><span class="n">parameters</span><span class="p">()}</span>
                                 <span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_parameters</span><span class="p">()</span>

<div class="viewcode-block" id="CLIP.initialize_parameters"><a class="viewcode-back" href="../../../generated/ggfm.models.CLIP.html#ggfm.models.CLIP.initialize_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

        <span class="n">proj_std</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">attn_std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="n">fc_std</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="k">for</span> <span class="n">block</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">resblocks</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">in_proj_weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">attn_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">attn</span><span class="o">.</span><span class="n">out_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">proj_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">c_fc</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">fc_std</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">block</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">c_proj</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">proj_std</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">width</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span></div>

<div class="viewcode-block" id="CLIP.build_attention_mask"><a class="viewcode-back" href="../../../generated/ggfm.models.CLIP.html#ggfm.models.CLIP.build_attention_mask">[docs]</a>    <span class="k">def</span> <span class="nf">build_attention_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># lazily create causal attention mask, with full attention between the vision tokens</span>
        <span class="c1"># pytorch uses additive attention mask; fill with -inf</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">)</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;-inf&quot;</span><span class="p">))</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">triu_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># zero out the lower diagonal</span>
        <span class="k">return</span> <span class="n">mask</span></div>

<div class="viewcode-block" id="CLIP.encode_image"><a class="viewcode-back" href="../../../generated/ggfm.models.CLIP.html#ggfm.models.CLIP.encode_image">[docs]</a>    <span class="k">def</span> <span class="nf">encode_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx_train</span><span class="p">,</span> <span class="n">g</span><span class="p">):</span>
        <span class="n">embs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="n">idx_train</span> <span class="o">=</span> <span class="n">idx_train</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">embs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">idx_train</span> <span class="o">=</span> <span class="n">idx_train</span>
        <span class="n">train_embs</span> <span class="o">=</span> <span class="n">embs</span><span class="p">[</span><span class="n">idx_train</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">train_embs</span></div>

<div class="viewcode-block" id="CLIP.encode_text"><a class="viewcode-back" href="../../../generated/ggfm.models.CLIP.html#ggfm.models.CLIP.encode_text">[docs]</a>    <span class="k">def</span> <span class="nf">encode_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_embedding</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>  <span class="c1"># [batch_size, n_ctx, d_model]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">positional_embedding</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="mi">2</span><span class="p">)</span>  <span class="c1"># NLD -&gt; LND, batch_size * context_length *emb_dim -&gt; context_length * batch_size  *emb_dim</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="mi">2</span><span class="p">)</span>  <span class="c1"># LND -&gt; NLD, context_length * batch_size *emb_dim -&gt; batch_size * context_length *emb_dim</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln_final</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># x.shape = [batch_size, n_ctx, transformer.width]</span>
        <span class="c1"># take features from the eot （end of token） embedding (eot_token is the highest number in each sequence)</span>
        <span class="c1"># so there is node need to shorten the context length</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">text</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)]</span>  <span class="c1">#</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_projection</span>
        <span class="k">return</span> <span class="n">x</span></div>

<div class="viewcode-block" id="CLIP.forward"><a class="viewcode-back" href="../../../generated/ggfm.models.CLIP.html#ggfm.models.CLIP.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">s_n</span><span class="p">,</span> <span class="n">t_n</span><span class="p">,</span> <span class="n">s_n_text</span><span class="p">,</span> <span class="n">t_n_text</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

        <span class="n">s_image_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_image</span><span class="p">(</span><span class="n">s_n</span><span class="p">,</span> <span class="n">g</span><span class="p">)</span>

        <span class="n">s_text_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">s_n_text</span><span class="p">)</span>

        <span class="n">t_text_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_text</span><span class="p">(</span><span class="n">t_n_text</span><span class="p">)</span>
        <span class="n">t_text_features</span> <span class="o">=</span> <span class="n">t_text_features</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">s_image_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">neigh_num</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">gnn_output</span><span class="p">)</span>
        <span class="n">t_text_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">t_text_features</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># normalized features</span>
        <span class="n">s_image_features</span> <span class="o">=</span> <span class="n">s_image_features</span> <span class="o">/</span> <span class="n">s_image_features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">s_text_features</span> <span class="o">=</span> <span class="n">s_text_features</span> <span class="o">/</span> <span class="n">s_text_features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">t_text_features</span> <span class="o">=</span> <span class="n">t_text_features</span> <span class="o">/</span> <span class="n">t_text_features</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># cosine similarity as logits</span>

        <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">s_image_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="c1"># logit_scale = self.logit_scale.exp()  # the temporature hyperparameter</span>
        <span class="c1"># logit_scale, s_image_features, s_text_features = Mv2SameDevice([logit_scale, s_image_features, s_text_features])</span>
        <span class="c1"># logits = logit_scale * s_image_features @ s_text_features.t()</span>
        <span class="c1"># loss_i = F.cross_entropy(logits, labels)</span>
        <span class="c1"># loss_t = F.cross_entropy(logits.T, labels)</span>
        <span class="c1"># node_loss = (loss_i + loss_t) / 2</span>

        <span class="c1"># logit_scale, s_image_features, t_text_features = Mv2SameDevice([logit_scale, s_image_features, t_text_features])</span>
        <span class="c1"># logits = logit_scale * s_image_features @ t_text_features.t()</span>
        <span class="c1"># loss_i = F.cross_entropy(logits, labels)</span>
        <span class="c1"># loss_t = F.cross_entropy(logits.T, labels)</span>
        <span class="c1"># gt_loss = (loss_i + loss_t)/2</span>

        <span class="c1"># logit_scale, s_text_features, t_text_features = Mv2SameDevice([logit_scale, s_text_features, t_text_features])</span>
        <span class="c1"># logits = logit_scale * s_text_features @ t_text_features.t()</span>
        <span class="c1"># loss_i = F.cross_entropy(logits, labels)</span>
        <span class="c1"># loss_t = F.cross_entropy(logits.T, labels)</span>
        <span class="c1"># tt_loss = (loss_i + loss_t)/2</span>

        <span class="c1"># shape = [global_batch_size, global_batch_size]</span>
        <span class="c1"># return all_loss</span>
        <span class="k">return</span> <span class="n">s_image_features</span><span class="p">,</span> <span class="n">s_text_features</span><span class="p">,</span> <span class="n">t_text_features</span><span class="p">,</span> <span class="n">labels</span></div></div>


<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">texts</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span> <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">truncate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the tokenized representation of given input string(s)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    texts : Union[str, List[str]]</span>
<span class="sd">        An input string or a list of input strings to tokenize</span>

<span class="sd">    context_length : int</span>
<span class="sd">        The context length to use; all CLIP models use 77 as the context length</span>

<span class="sd">    truncate: bool</span>
<span class="sd">        Whether to truncate the text in case its encoding is longer than the context length</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    A two-dimensional tensor containing the resulting tokens, shape = [number of input strings, context_length]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span><span class="n">texts</span><span class="p">]</span>

    <span class="n">sot_token</span> <span class="o">=</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;&lt;|startoftext|&gt;&quot;</span><span class="p">]</span>
    <span class="n">eot_token</span> <span class="o">=</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encoder</span><span class="p">[</span><span class="s2">&quot;&lt;|endoftext|&gt;&quot;</span><span class="p">]</span>
    <span class="n">all_tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">sot_token</span><span class="p">]</span> <span class="o">+</span> <span class="n">_tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">eot_token</span><span class="p">]</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">]</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">),</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tokens</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_tokens</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">context_length</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">truncate</span><span class="p">:</span>
                <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokens</span><span class="p">[:</span><span class="n">context_length</span><span class="p">]</span>
                <span class="n">tokens</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">eot_token</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input </span><span class="si">{</span><span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2"> is too long for context length </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="c1">###### GraphGPT conv layers ######</span>
<span class="c1"># class GraphLlamaConfig(LlamaConfig):</span>
<span class="c1">#     model_type = &quot;GraphLlama&quot;</span>

<span class="k">class</span> <span class="nc">GraphPretrainConfig</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dictionary</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">dictionary</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">find_all_linear_names</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Find all linear layer names in the model</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">cls</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span>
    <span class="n">lora_module_names</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">cls</span><span class="p">):</span>
            <span class="n">names</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
            <span class="n">lora_module_names</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">names</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


    <span class="k">if</span> <span class="s1">&#39;lm_head&#39;</span> <span class="ow">in</span> <span class="n">lora_module_names</span><span class="p">:</span> <span class="c1"># needed for 16-bit</span>
        <span class="n">lora_module_names</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s1">&#39;lm_head&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">lora_module_names</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_model_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrain_model_path</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load pretrain model</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model_name</span>
<span class="sd">    pretrain_model_path</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># load conig json</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;load args from pretrain model:&quot;</span> <span class="o">+</span> <span class="n">pretrain_model_path</span><span class="p">)</span>

    <span class="k">assert</span> <span class="n">osp</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">osp</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;config.json&#39;</span><span class="p">)),</span> <span class="s1">&#39;config.json missing&#39;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">osp</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;config.json&#39;</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">config_dict</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">GraphPretrainConfig</span><span class="p">(</span><span class="n">config_dict</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model_name</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">pkl_files</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">osp</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pretrain_model_path</span><span class="p">,</span> <span class="s1">&#39;*.pkl&#39;</span><span class="p">))</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pkl_files</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1"># print(state_dict.keys())</span>
    <span class="k">if</span> <span class="s1">&#39;logit_scale&#39;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;logit_scale&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loading graph pre train model&#39;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">gnn</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transfer parameters from clip graph to GNN</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    clip_graph</span>
<span class="sd">    gnn</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">)</span>
    <span class="n">gnn_state_dict</span> <span class="o">=</span> <span class="n">clip_graph</span><span class="o">.</span><span class="n">gnn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
    <span class="n">gnn</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">gnn_state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gnn</span>

<div class="viewcode-block" id="GraphLlamaModel"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaModel.html#ggfm.models.GraphLlamaModel">[docs]</a><span class="k">class</span> <span class="nc">GraphLlamaModel</span><span class="p">(</span><span class="n">LlamaModel</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Llama model</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># config_class = GraphLlamaConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">LlamaConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GraphLlamaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;graph_tower&quot;</span><span class="p">):</span>
            <span class="c1"># HACK: for FSDP</span>
            <span class="c1"># self.vision_tower = [CLIPVisionModel.from_pretrained(config.graph_tower)]</span>
            <span class="c1"># self.arxiv_projector = nn.Linear(config.graph_hidden_size, config.hidden_size)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;config.graph_tower:&quot;</span> <span class="o">+</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s1">&#39;MPNN&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">MPNN</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                                        <span class="n">hidden_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                                        <span class="n">out_channels</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                        <span class="n">if_param</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gcn_arxiv&quot;</span><span class="p">:</span>

                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv_pub&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>

            <span class="c1"># self.vision_tower = CLIPVisionModel.from_pretrained(config.mm_vision_tower)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_graph_proj&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

<div class="viewcode-block" id="GraphLlamaModel.get_graph_tower"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaModel.html#ggfm.models.GraphLlamaModel.get_graph_tower">[docs]</a>    <span class="k">def</span> <span class="nf">get_graph_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">graph_tower</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_tower&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_tower</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">graph_tower</span></div>

<div class="viewcode-block" id="GraphLlamaModel.initialize_graph_modules"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaModel.html#ggfm.models.GraphLlamaModel.initialize_graph_modules">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_graph_modules</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">,</span> <span class="n">graph_select_layer</span><span class="p">,</span>
                                 <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fsdp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>  <span class="c1"># TODO: modify this function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;graph_tower:&quot;</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_tower&#39;</span><span class="p">):</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;graph_tower:&quot;</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s1">&#39;MPNN&#39;</span><span class="p">:</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">MPNN</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span>
                                   <span class="n">hidden_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                                   <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                   <span class="n">if_param</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gcn_arxiv&quot;</span><span class="p">:</span>

                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">GNN</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="c1"># graph_tower = MPNN(in_channels = self.config.graph_hidden_size, hidden_channels = self.config.graph_hidden_size * 2, out_channels = self.config.graph_hidden_size, dropout = 0.1, num_layers = 2)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">==</span> <span class="s2">&quot;clip_gt_arxiv_pub&quot;</span><span class="p">:</span>
                <span class="n">clip_graph</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">load_model_pretrained</span><span class="p">(</span><span class="n">CLIP</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_transformer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
                <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">transfer_param_tograph</span><span class="p">(</span><span class="n">clip_graph</span><span class="p">,</span> <span class="n">graph_tower</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;self graph_tower:&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">)</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span>
        <span class="n">graph_tower</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fsdp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">fsdp</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="p">[</span><span class="n">graph_tower</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_proj</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_select_layer</span> <span class="o">=</span> <span class="n">graph_select_layer</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;graph_projector&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pretrain_graph_mlp_adapter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">graph_projector_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">({</span><span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">graph_projector_weights</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span></div>

<div class="viewcode-block" id="GraphLlamaModel.forward"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaModel.html#ggfm.models.GraphLlamaModel.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="c1"># graph_node_reps: Optional[torch.FloatTensor] = None,</span>
            <span class="c1"># edge_index_reps: Optional[torch.FloatTensor] = None,</span>
            <span class="n">graph_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Data</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># ) -&gt; Union[Tuple, BaseModelOutputWithPast]:</span>
    <span class="p">):</span>

        <span class="c1"># HACK: replace back original embeddings for LLaVA pretraining</span>
        <span class="n">orig_embeds_params</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;orig_embeds_params&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="c1"># if orig_embeds_params is not None:</span>
        <span class="c1">#     orig_embeds_params = orig_embeds_params[0]</span>
        <span class="c1">#     with torch.no_grad():</span>
        <span class="c1">#         self.get_input_embeddings().weight.data[:-2] = orig_embeds_params[:-2].data</span>

        <span class="k">if</span> <span class="n">inputs_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_tokens</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="n">graph_tower</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">graph_tower</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span> <span class="ow">and</span> <span class="n">graph_data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># TODO: this is a modified multimodal LLM -- Haotian Liu</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                    <span class="c1"># variable length images</span>
                    <span class="n">graph_node_features</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="n">Data</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">graph_data</span><span class="p">:</span>
                            <span class="c1"># print(g)</span>
                            <span class="n">node_forward_out</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                        <span class="k">for</span> <span class="n">g_dict</span> <span class="ow">in</span> <span class="n">graph_data</span><span class="p">:</span>
                            <span class="n">node_forward_out_1</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g_dict</span><span class="p">[</span><span class="s1">&#39;graph_1&#39;</span><span class="p">])</span>
                            <span class="n">node_forward_out_2</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">(</span><span class="n">g_dict</span><span class="p">[</span><span class="s1">&#39;graph_2&#39;</span><span class="p">])</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out_1</span><span class="p">)</span>
                            <span class="n">graph_node_features</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_forward_out_2</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;graph_node_reps is expected to be a list but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                <span class="c1"># if type(graph_node_features[0]) is not dict:</span>
                <span class="n">graph_node_features</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="p">(</span><span class="n">node_feature</span><span class="p">)</span> <span class="k">for</span> <span class="n">node_feature</span> <span class="ow">in</span> <span class="n">graph_node_features</span><span class="p">]</span>
                <span class="c1"># else:</span>
                <span class="c1">#     graph_node_features = [{&#39;graph_1&#39;: self.graph_projector(node_feature[&#39;graph_1&#39;]), &#39;graph_2&#39;: self.graph_projector(node_feature[&#39;graph_2&#39;])} for node_feature in graph_node_features]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;graph_node_reps is expected to be a list but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">graph_data</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="n">dummy_graph_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">dummy_graph_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph_projector</span><span class="p">(</span><span class="n">dummy_graph_features</span><span class="p">)</span>

            <span class="n">new_input_embeds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">cur_graph_idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">cur_input_ids</span><span class="p">,</span> <span class="n">cur_input_embeds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># multimodal LLM, but the current sample is not multimodal</span>
                    <span class="n">cur_input_embeds</span> <span class="o">=</span> <span class="n">cur_input_embeds</span> <span class="o">+</span> <span class="p">(</span><span class="mf">0.</span> <span class="o">*</span> <span class="n">dummy_graph_features</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_input_embeds</span><span class="p">)</span>
                    <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_start_end</span><span class="p">:</span>
                    <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span>
                    <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="p">(</span>
                            <span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_end_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The number of graph start tokens and graph end tokens should be the same.&quot;</span><span class="p">)</span>
                    <span class="n">graph_start_tokens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="c1"># print(graph_start_tokens)</span>
                    <span class="k">for</span> <span class="n">graph_start_token_pos</span> <span class="ow">in</span> <span class="n">graph_start_tokens</span><span class="p">:</span>
                        <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">cur_input_embeds</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                        <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                        <span class="k">if</span> <span class="n">cur_input_ids</span><span class="p">[</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_end_token</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The graph end token should follow the graph start token.&quot;</span><span class="p">)</span>
                        <span class="k">if</span> <span class="n">orig_embeds_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">graph_start_token_pos</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                                                              <span class="n">cur_input_embeds</span><span class="p">[</span>
                                                              <span class="n">graph_start_token_pos</span><span class="p">:</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                                                              <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span>
                                                                                  <span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">2</span><span class="p">],</span>
                                                              <span class="n">cur_input_embeds</span><span class="p">[</span>
                                                              <span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span>
                                                             <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                                                              <span class="n">cur_graph_features</span><span class="p">,</span> <span class="n">cur_input_embeds</span><span class="p">[</span>
                                                                                  <span class="n">graph_start_token_pos</span> <span class="o">+</span> <span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]),</span>
                                                             <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_new_input_embeds</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">cur_graph_features</span> <span class="o">=</span> <span class="n">graph_node_features</span><span class="p">[</span><span class="n">cur_graph_idx</span><span class="p">]</span>
                    <span class="n">num_patches</span> <span class="o">=</span> <span class="n">cur_graph_features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="n">num_patches</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;The number of graph patch tokens should be the same as the number of graph patches.&quot;</span><span class="p">)</span>
                    <span class="n">masked_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">cur_input_ids</span> <span class="o">==</span> <span class="n">graph_tower</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">graph_patch_token</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">mask_index_start</span> <span class="o">=</span> <span class="n">masked_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">masked_indices</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">mask_index_start</span><span class="p">,</span> <span class="n">mask_index_start</span> <span class="o">+</span> <span class="n">num_patches</span><span class="p">,</span>
                                                       <span class="n">device</span><span class="o">=</span><span class="n">masked_indices</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">masked_indices</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The graph patch tokens should be consecutive.&quot;</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">orig_embeds_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">mask_index_start</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span>
                                                          <span class="n">cur_graph_features</span><span class="p">,</span>
                                                          <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">mask_index_start</span> <span class="o">+</span> <span class="n">num_patches</span><span class="p">:]</span><span class="o">.</span><span class="n">detach</span><span class="p">()),</span>
                                                         <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">cur_new_input_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cur_input_embeds</span><span class="p">[:</span><span class="n">mask_index_start</span><span class="p">],</span> <span class="n">cur_graph_features</span><span class="p">,</span>
                                                          <span class="n">cur_input_embeds</span><span class="p">[</span><span class="n">mask_index_start</span> <span class="o">+</span> <span class="n">num_patches</span><span class="p">:]),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">new_input_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cur_new_input_embeds</span><span class="p">)</span>
                    <span class="n">cur_graph_idx</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># print(cur_graph_idx)</span>
            <span class="c1"># print(len(graph_node_features))</span>
            <span class="k">assert</span> <span class="n">cur_graph_idx</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">graph_node_features</span><span class="p">)</span>
            <span class="n">inputs_embeds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">new_input_embeds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">GraphLlamaModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="GraphLlamaForCausalLM"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM">[docs]</a><span class="k">class</span> <span class="nc">GraphLlamaForCausalLM</span><span class="p">(</span><span class="n">LlamaForCausalLM</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph Llama model for causal language modeling</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># config_class = GraphLlamaConfig</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LlamaForCausalLM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GraphLlamaModel</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># Initialize weights and apply final processing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_init</span><span class="p">()</span>

<div class="viewcode-block" id="GraphLlamaForCausalLM.get_model"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM.get_model">[docs]</a>    <span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span></div>

<div class="viewcode-block" id="GraphLlamaForCausalLM.get_graph_tower"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM.get_graph_tower">[docs]</a>    <span class="k">def</span> <span class="nf">get_graph_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span></div>

<div class="viewcode-block" id="GraphLlamaForCausalLM.get_vision_tower"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM.get_vision_tower">[docs]</a>    <span class="k">def</span> <span class="nf">get_vision_tower</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span>
        <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">graph_tower</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph_tower</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
            <span class="n">graph_tower</span> <span class="o">=</span> <span class="n">graph_tower</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">graph_tower</span></div>

<div class="viewcode-block" id="GraphLlamaForCausalLM.forward"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="c1"># graph_node_reps: Optional[torch.FloatTensor] = None,</span>
        <span class="c1"># edge_index_reps: Optional[torch.FloatTensor] = None,</span>
        <span class="n">graph_data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Data</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="c1"># ) -&gt; Union[Tuple, CausalLMOutputWithPast]:</span>
    <span class="p">):</span>
        <span class="n">output_attentions</span> <span class="o">=</span> <span class="n">output_attentions</span> <span class="k">if</span> <span class="n">output_attentions</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_attentions</span>
        <span class="n">output_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">output_hidden_states</span> <span class="k">if</span> <span class="n">output_hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">output_hidden_states</span>
        <span class="p">)</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>

        <span class="c1"># decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="c1"># graph_node_reps=graph_node_reps,</span>
            <span class="c1"># edge_index_reps=edge_index_reps</span>
            <span class="n">graph_data</span> <span class="o">=</span> <span class="n">graph_data</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Shift so that tokens &lt; n predict n</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="c1"># Flatten the tokens</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># Enable model/pipeline parallelism</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">shift_logits</span><span class="p">,</span> <span class="n">shift_labels</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">logits</span><span class="p">,)</span> <span class="o">+</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,)</span> <span class="o">+</span> <span class="n">output</span> <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">CausalLMOutputWithPast</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="GraphLlamaForCausalLM.prepare_inputs_for_generation"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM.prepare_inputs_for_generation">[docs]</a>    <span class="k">def</span> <span class="nf">prepare_inputs_for_generation</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">past_key_values</span><span class="p">:</span>
            <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># if `inputs_embeds` are passed, we only want to use them in the 1st generation step</span>
        <span class="k">if</span> <span class="n">inputs_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs_embeds&quot;</span><span class="p">:</span> <span class="n">inputs_embeds</span><span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">input_ids</span><span class="p">}</span>

        <span class="n">model_inputs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;past_key_values&quot;</span><span class="p">:</span> <span class="n">past_key_values</span><span class="p">,</span>
                <span class="s2">&quot;use_cache&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;use_cache&quot;</span><span class="p">),</span>
                <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">attention_mask</span><span class="p">,</span>
                <span class="s2">&quot;graph_data&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;graph_data&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                <span class="c1"># &quot;edge_index_reps&quot;: kwargs.get(&quot;edge_index_reps&quot;, None),</span>
            <span class="p">}</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">model_inputs</span></div>

<div class="viewcode-block" id="GraphLlamaForCausalLM.initialize_graph_tokenizer"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphLlamaForCausalLM.html#ggfm.models.GraphLlamaForCausalLM.initialize_graph_tokenizer">[docs]</a>    <span class="k">def</span> <span class="nf">initialize_graph_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">use_graph_start_end</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
                                    <span class="n">tune_graph_mlp_adapter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">vision_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span><span class="o">.</span><span class="n">config</span>
        <span class="n">vision_config</span><span class="o">.</span><span class="n">use_graph_start_end</span> <span class="o">=</span> <span class="n">use_graph_start_end</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span><span class="p">],</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">use_graph_start_end</span><span class="p">:</span>
            <span class="n">num_new_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">([</span><span class="n">DEFAULT_G_START_TOKEN</span><span class="p">,</span> <span class="n">DEFAULT_G_END_TOKEN</span><span class="p">],</span> <span class="n">special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))</span>
            <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_start_token</span><span class="p">,</span> <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_end_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">([</span><span class="n">DEFAULT_G_START_TOKEN</span><span class="p">,</span> <span class="n">DEFAULT_G_END_TOKEN</span><span class="p">])</span>

            <span class="k">if</span> <span class="n">num_new_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">input_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
                <span class="n">output_embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>

                <span class="n">input_embeddings_avg</span> <span class="o">=</span> <span class="n">input_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">output_embeddings_avg</span> <span class="o">=</span> <span class="n">output_embeddings</span><span class="p">[:</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                    <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">input_embeddings_avg</span>
                <span class="n">output_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">output_embeddings_avg</span>

            <span class="k">if</span> <span class="n">tune_graph_mlp_adapter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">orig_embeds_params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)]</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">pretrain_graph_mlp_adapter</span><span class="p">:</span>
                <span class="n">mm_projector_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                <span class="n">embed_tokens_weight</span> <span class="o">=</span> <span class="n">mm_projector_weights</span><span class="p">[</span><span class="s1">&#39;model.embed_tokens.weight&#39;</span><span class="p">]</span>
                <span class="k">assert</span> <span class="n">num_new_tokens</span> <span class="o">==</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                    <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">embed_tokens_weight</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span>
                <span class="k">elif</span> <span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_new_tokens</span><span class="p">:</span>
                    <span class="n">input_embeddings</span><span class="p">[</span><span class="o">-</span><span class="n">num_new_tokens</span><span class="p">:]</span> <span class="o">=</span> <span class="n">embed_tokens_weight</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected embed_tokens_weight shape. Pretrained: </span><span class="si">{</span><span class="n">embed_tokens_weight</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Current: </span><span class="si">{</span><span class="n">input_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Numer of new tokens: </span><span class="si">{</span><span class="n">num_new_tokens</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="n">vision_config</span><span class="o">.</span><span class="n">graph_patch_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">convert_tokens_to_ids</span><span class="p">([</span><span class="n">DEFAULT_GRAPH_PATCH_TOKEN</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span></div></div>

<span class="c1"># AutoConfig.register(&quot;GraphLlama&quot;, GraphLlamaConfig)</span>
<span class="c1"># AutoModelForCausalLM.register(GraphLlamaConfig, GraphLlamaForCausalLM)</span>



<div class="viewcode-block" id="GraphGPT_pl"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphGPT_pl.html#ggfm.models.GraphGPT_pl">[docs]</a><span class="k">class</span> <span class="nc">GraphGPT_pl</span><span class="p">(</span><span class="n">LightningModule</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Graph GPT model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">training_args</span><span class="p">,</span> <span class="n">model_args</span><span class="p">,</span> <span class="n">data_args</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
                 <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_args</span> <span class="o">=</span> <span class="n">training_args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_args</span> <span class="o">=</span> <span class="n">model_args</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_args</span> <span class="o">=</span> <span class="n">data_args</span>
        <span class="n">compute_dtype</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">float16</span> <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">fp16</span> <span class="k">else</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bf16</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

        <span class="n">bnb_model_from_pretrained_args</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1">## load 4 8 bit</span>
        <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]:</span>
            <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BitsAndBytesConfig</span>
            <span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">prepare_model_for_int8_training</span>
            <span class="n">bnb_model_from_pretrained_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
                <span class="n">device_map</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="n">training_args</span><span class="o">.</span><span class="n">device</span><span class="p">},</span>
                <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span>
                <span class="n">load_in_8bit</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="o">==</span> <span class="mi">8</span><span class="p">,</span>
                <span class="n">quantization_config</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">(</span>
                    <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="o">==</span> <span class="mi">4</span><span class="p">,</span>
                    <span class="n">load_in_8bit</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="o">==</span> <span class="mi">8</span><span class="p">,</span>
                    <span class="n">llm_int8_threshold</span><span class="o">=</span><span class="mf">6.0</span><span class="p">,</span>
                    <span class="n">llm_int8_has_fp16_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">compute_dtype</span><span class="p">,</span>
                    <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">double_quant</span><span class="p">,</span>
                    <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">quant_type</span>  <span class="c1"># {&#39;fp4&#39;, &#39;nf4&#39;}</span>
                <span class="p">)</span>
            <span class="p">))</span>

        <span class="k">if</span> <span class="n">model_args</span><span class="o">.</span><span class="n">graph_tower</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">GraphLlamaForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_args</span><span class="o">.</span><span class="n">model_name_or_path</span><span class="p">,</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">cache_dir</span><span class="p">,</span>
                <span class="o">**</span><span class="n">bnb_model_from_pretrained_args</span>
            <span class="p">)</span>  <span class="c1">## TODO: add real Graph Llama model</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">LlamaForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">model_args</span><span class="o">.</span><span class="n">model_name_or_path</span><span class="p">,</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">cache_dir</span><span class="p">,</span>
                <span class="o">**</span><span class="n">bnb_model_from_pretrained_args</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretrain_graph_model_path</span> <span class="o">+</span> <span class="n">model_args</span><span class="o">.</span><span class="n">graph_tower</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="n">model_args</span><span class="o">.</span><span class="n">freeze_backbone</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">torch_dtype</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">float32</span> <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">fp16</span> <span class="k">else</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bf16</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_int8_training</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
                                                         <span class="n">use_gradient_checkpointing</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">gradient_checkpointing</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">gradient_checkpointing</span> <span class="ow">and</span> <span class="n">model_args</span><span class="o">.</span><span class="n">graph_tower</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;enable_input_require_grads&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">enable_input_require_grads</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">def</span> <span class="nf">make_inputs_require_grad</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">make_inputs_require_grad</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">lora_enable</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span>
            <span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
                <span class="n">r</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">lora_r</span><span class="p">,</span>
                <span class="n">lora_alpha</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">lora_alpha</span><span class="p">,</span>
                <span class="n">target_modules</span><span class="o">=</span><span class="n">find_all_linear_names</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">),</span>
                <span class="n">lora_dropout</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">lora_dropout</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">lora_bias</span><span class="p">,</span>
                <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="o">==</span> <span class="mi">16</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">fp16</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Adding LoRA adapters...&quot;</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">model_args</span><span class="o">.</span><span class="n">graph_tower</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_graph_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">initialize_graph_modules</span><span class="p">(</span>
                <span class="n">graph_tower</span><span class="o">=</span><span class="n">model_args</span><span class="o">.</span><span class="n">graph_tower</span><span class="p">,</span>
                <span class="n">graph_select_layer</span><span class="o">=</span><span class="n">model_args</span><span class="o">.</span><span class="n">graph_select_layer</span><span class="p">,</span>
                <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="n">model_args</span><span class="o">.</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">,</span>
                <span class="n">fsdp</span><span class="o">=</span><span class="kc">None</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_graph_tower</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">compute_dtype</span><span class="p">)</span>
            <span class="c1"># graph_config = model_graph_dict[&#39;graph_config&#39;]</span>

            <span class="c1"># data_args.graph_token_len = model_graph_dict[&#39;graph_token_len&#39;]</span>
            <span class="c1"># data_args.graph_processor = model_graph_dict[&#39;graph_processor&#39;]</span>
            <span class="n">data_args</span><span class="o">.</span><span class="n">is_graph</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">tune_graph_mlp_adapter</span> <span class="o">=</span> <span class="n">training_args</span><span class="o">.</span><span class="n">tune_graph_mlp_adapter</span> <span class="o">=</span> <span class="n">model_args</span><span class="o">.</span><span class="n">tune_graph_mlp_adapter</span>
            <span class="k">if</span> <span class="n">model_args</span><span class="o">.</span><span class="n">tune_graph_mlp_adapter</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">graph_projector</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">freeze_graph_mlp_adapter</span> <span class="o">=</span> <span class="n">training_args</span><span class="o">.</span><span class="n">freeze_graph_mlp_adapter</span>
            <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">freeze_graph_mlp_adapter</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">graph_projector</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_model</span><span class="p">()</span><span class="o">.</span><span class="n">graph_projector</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">compute_dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">training_args</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_graph_start_end</span> <span class="o">=</span> <span class="n">data_args</span><span class="o">.</span><span class="n">use_graph_start_end</span> <span class="o">=</span> <span class="n">model_args</span><span class="o">.</span><span class="n">use_graph_start_end</span>
            <span class="c1"># graph_config.use_graph_start_end = training_args.use_graph_start_end = model_args.use_graph_start_end</span>
            <span class="n">training_args</span><span class="o">.</span><span class="n">use_graph_start_end</span> <span class="o">=</span> <span class="n">model_args</span><span class="o">.</span><span class="n">use_graph_start_end</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sep_graph_conv_front</span> <span class="o">=</span> <span class="n">data_args</span><span class="o">.</span><span class="n">sep_graph_conv_front</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">initialize_graph_tokenizer</span><span class="p">(</span><span class="n">use_graph_start_end</span><span class="o">=</span><span class="n">model_args</span><span class="o">.</span><span class="n">use_graph_start_end</span><span class="p">,</span>
                                                  <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
                                                  <span class="n">tune_graph_mlp_adapter</span><span class="o">=</span><span class="n">model_args</span><span class="o">.</span><span class="n">tune_graph_mlp_adapter</span><span class="p">,</span>
                                                  <span class="n">pretrain_graph_mlp_adapter</span><span class="o">=</span><span class="n">model_args</span><span class="o">.</span><span class="n">pretrain_graph_mlp_adapter</span><span class="p">)</span>

            <span class="n">params_no_grad</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bits</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">]:</span>
                <span class="kn">from</span> <span class="nn">peft.tuners.lora</span> <span class="kn">import</span> <span class="n">LoraLayer</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">LoraLayer</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bf16</span><span class="p">:</span>
                            <span class="n">module</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>
                    <span class="k">if</span> <span class="s1">&#39;norm&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                        <span class="n">module</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                    <span class="k">if</span> <span class="s1">&#39;lm_head&#39;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="s1">&#39;embed_tokens&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">):</span>
                            <span class="k">if</span> <span class="n">training_args</span><span class="o">.</span><span class="n">bf16</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
                                <span class="n">module</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;************************** parameters: #&#39;</span><span class="p">,</span>
                  <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">))</span>
            <span class="n">tuned_params</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                    <span class="n">tuned_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">tuned_params</span><span class="p">)</span>

<div class="viewcode-block" id="GraphGPT_pl.training_step"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphGPT_pl.html#ggfm.models.GraphGPT_pl.training_step">[docs]</a>    <span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">])</span>
        <span class="n">loss_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_dict</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

        <span class="n">log_dict</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">log_dict</span><span class="p">,</span> <span class="n">on_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sync_dist</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">bs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span></div>

<div class="viewcode-block" id="GraphGPT_pl.configure_optimizers"><a class="viewcode-back" href="../../../generated/ggfm.models.GraphGPT_pl.html#ggfm.models.GraphGPT_pl.configure_optimizers">[docs]</a>    <span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Prepare optimizer and schedule (linear warmup and decay)&quot;&quot;&quot;</span>
        <span class="c1"># no_decay = [&quot;bias&quot;, &quot;LayerNorm.weight&quot;]</span>
        <span class="c1"># if IS_STAGE2:</span>

        <span class="n">optimizer_grouped_parameters</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()],</span> <span class="s2">&quot;lr_scale&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">]</span>
            <span class="p">}</span>
        <span class="p">]</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">optimizer_grouped_parameters</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_args</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>

        <span class="c1"># scheduler = get_linear_schedule_with_warmup(</span>
        <span class="c1">#     optimizer,</span>
        <span class="c1">#     num_warmup_steps=self.training_args.warmup_steps,</span>
        <span class="c1">#     num_training_steps=self.trainer.estimated_stepping_batches,</span>
        <span class="c1"># )</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_cosine_schedule_with_warmup</span><span class="p">(</span>
            <span class="n">optimizer</span><span class="p">,</span>
            <span class="n">num_warmup_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_args</span><span class="o">.</span><span class="n">warmup_steps</span><span class="p">,</span>
            <span class="n">num_training_steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">estimated_stepping_batches</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="s2">&quot;frequency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">optimizer</span><span class="p">],</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, BUPT-GAMMA LAB.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>